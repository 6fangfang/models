# Builtin Configurations(DO NOT CHANGE THESE CONFIGURATIONS unless you know exactly what you are doing)
is_distributed: True
debug: False
not_val: False
continue_train: False
model_arts: False

# descriptions
model: 'DeepLab v2'

# URL for model train and eval todo need modified according to the experimental environment
data_dir: "/home/ma-user/work/datasets/gtav"
data_dir_target: "/home/ma-user/work/datasets/Cityscapes"
restore_from: "./src/advnet/Source_only_35.93.ckpt"
#restore_from: "/home/seaelm/repos/Advseg/src/advnet/Source_only_35.93.ckpt"
snapshot_dir: "./checkpoint/"
save_result: "./result/cityscapes"


data_list: "./src/dataset/gta5_list/train.txt"
data_list_target: "./src/dataset/cityscapes_list"
# environment
device_target: "Ascend"
rank: 0
group_size: 1

# model export and infer_310
file_format: "MINDIR"
file_name: "./ascend310_infer/model"
output_path: "./preprocess_Result"
predict_path: "./result_Files"



# ==================================================================
# Options
seed: 1234
set: "train"
# Options: images setting
input_size: [ 1280,720 ]
input_size_target: [ 1024,512 ]
output_size: [ 1024,2048 ]
# Options: train setting
batch_size: 1
iter_size: 1
num_workers: 8
num_steps: 250000
save_pred_every: 2000
num_steps_stop: 250000
# Options: models setting
num_classes: 19
# Options: SGD and learning rate setting
learning_rate: 0.00025 #2.5e-4
power: 0.9
momentum: 0.9
weight_decay: 0.0005
# Options: Adam and learning rate
learning_rate_D: 0.0001 #1e-4
# Options: loss
lambda_: [ 0.1,2e-4,0.001 ]







