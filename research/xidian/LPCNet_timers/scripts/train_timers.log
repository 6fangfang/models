[WARNING] ME(1332955:281473649238048,_GeneratorWorkerMp-10):2024-10-31-03:51:56.479.31 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] ME(1332998:281473649238048,_GeneratorWorkerMp-19):2024-10-31-03:51:59.400.291 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] ME(1333239:281473649238048,_GeneratorWorkerMp-49):2024-10-31-03:52:12.397.17 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.177.048 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op940] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.198.539 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op946] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.208.973 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op948] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.214.007 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op950] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.219.862 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op952] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.226.073 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op955] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.228.489 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op956] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-03:52:46.230.227 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op957] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-04:01:29.264.504 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 2
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-04:01:29.264.692 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 5
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-04:01:29.264.752 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 11
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-04:01:29.264.802 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 14
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-04:01:29.264.852 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 17
[WARNING] DEVICE(1332679,ffffb0e06020,python):2024-10-31-04:01:29.265.006 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 8
[WARNING] MD(1332679,fff6867cf080,python):2024-10-31-04:01:44.019.462 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:195] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function.
[WARNING] MD(1332679,fff685fbf080,python):2024-10-31-04:01:44.019.725 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:752] DetectPerBatchTime] Bad performance attention, it takes more than 25 seconds to fetch a batch of data from dataset pipeline, which might result `GetNext` timeout problem. You may test dataset processing performance(with creating dataset iterator) and optimize it.
epoch: 1 step: 40587, loss is 2.8436086177825928
Train epoch time: 17998154.631 ms, per step time: 443.446 ms
epoch: 2 step: 40587, loss is 2.5010933876037598
Train epoch time: 17798568.105 ms, per step time: 438.529 ms
epoch: 3 step: 40587, loss is 2.5889015197753906
Train epoch time: 17114754.563 ms, per step time: 421.681 ms
