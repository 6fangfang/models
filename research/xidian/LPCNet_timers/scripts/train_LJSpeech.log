[WARNING] ME(57550:281472918650912,_GeneratorWorkerMp-10):2024-10-28-06:05:38.651.111 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] ME(57556:281472918650912,_GeneratorWorkerMp-16):2024-10-28-06:05:38.651.691 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] ME(57555:281472918650912,_GeneratorWorkerMp-15):2024-10-28-06:05:38.651.954 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] ME(57597:281472918650912,_GeneratorWorkerMp-26):2024-10-28-06:05:41.918.775 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] ME(57844:281472918650912,_GeneratorWorkerMp-50):2024-10-28-06:05:54.675.760 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] ME(57841:281472918650912,_GeneratorWorkerMp-47):2024-10-28-06:05:54.677.112 [mindspore/dataset/engine/queue.py:125] Using shared memory queue, but rowsize is larger than allocated memory max_rowsize 6291456 current rowsize 120519680
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.303.018 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op940] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.323.966 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op946] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.334.233 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op948] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.339.151 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op950] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.344.848 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op952] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.350.935 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op955] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.353.294 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op956] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:06:32.355.012 [mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:330] FilterRaisedOrReducePrecisionMatchedKernelInfo] Operator:[Gradients/Default/network-MyTrainStep/network-WithLossLPCNet/backbone-LPCNet/decoder-Decoder/gradStridedSlice/StridedSliceGrad-op957] don't support int64, reduce precision from int64 to int32.
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:13:30.304.291 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 2
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:13:30.304.469 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 5
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:13:30.304.537 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 11
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:13:30.304.597 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 14
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:13:30.304.655 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 17
[WARNING] DEVICE(57319,ffff85548020,python):2024-10-28-06:13:30.304.835 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_assign.cc:1944] InsertEventForCallCommSubGraph] Cannot find comm group for sub comm graph label id 8
[WARNING] MD(57319,fffbe37ef080,python):2024-10-28-06:13:44.600.211 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc:195] operator()] Bad performance attention, it takes more than 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameter num_parallel_workers in GeneratorDataset / optimize the efficiency of obtaining samples in the user-defined generator function.
[WARNING] MD(57319,fffbe2fdf080,python):2024-10-28-06:13:44.600.497 [mindspore/ccsrc/minddata/dataset/engine/datasetops/device_queue_op.cc:752] DetectPerBatchTime] Bad performance attention, it takes more than 25 seconds to fetch a batch of data from dataset pipeline, which might result `GetNext` timeout problem. You may test dataset processing performance(with creating dataset iterator) and optimize it.
epoch: 1 step: 8970, loss is 3.454582452774048
Train epoch time: 4331859.958 ms, per step time: 482.928 ms
epoch: 2 step: 8970, loss is 3.3297922611236572
Train epoch time: 3741711.718 ms, per step time: 417.136 ms
epoch: 3 step: 8970, loss is 3.35798978805542
Train epoch time: 3742139.504 ms, per step time: 417.184 ms
epoch: 4 step: 8970, loss is 3.3087029457092285
Train epoch time: 3738787.871 ms, per step time: 416.810 ms

