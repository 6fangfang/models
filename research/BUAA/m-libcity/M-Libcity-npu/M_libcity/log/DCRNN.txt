time="2023-10-13T10:54:49+08:00" level=info msg="init logger successful" file="init.go:49" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:54:49+08:00" level=info msg="current user 1000:1000" file="init.go:51" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:54:54+08:00" level=warning msg="report event InitStart failed: send training-event info to algorancher failed, err: Post \"https://modelarts.cn-east-321.nbaicc.com/v2/17c194e82d5f4ec68a451515b77a1b5b/training-jobs/2c4fde60-364b-472d-a00f-922d0618e076/tasks/worker-0/reports/training-event\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" file="event.go:51" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:54:54+08:00" level=info msg="init command: bash /home/ma-user/training/init.sh ''" file="init.go:75" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:54:54+08:00" level=info msg="scc is already installed, skipping this step..." Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:54:54+08:00" level=info msg="[init] toolkit_obs_upload_pid = 56" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:54:54+08:00" level=info msg="[init] running at 2023-10-13-10:54:54" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:54:54+08:00" level=info msg="[init] ip of the pod: 172.16.0.78" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:54:54+08:00" level=info msg="local dir = /home/ma-user/modelarts/log/" file="upload.go:193" Command=obs/upload Component=ma-training-toolkit Platform=ModelArts-Service Task=
time="2023-10-13T10:54:54+08:00" level=info msg="obs dir = s3://modelarts-training-log-cneast321/2c4fde60-364b-472d-a00f-922d0618e076/worker-0" file="upload.go:196" Command=obs/upload Component=ma-training-toolkit Platform=ModelArts-Service Task=
time="2023-10-13T10:54:54+08:00" level=info msg="start the periodic upload task, upload Period = 5 seconds " file="upload.go:206" Command=obs/upload Component=ma-training-toolkit Platform=ModelArts-Service Task=
time="2023-10-13T10:54:54+08:00" level=info msg="[task]Detect item: disk-size shm" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:54:55+08:00" level=info msg="[detect] code: 0, message: ok, item: disk-size shm" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:54:55+08:00" level=info msg="[task]Detect item: dns" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:11+08:00" level=info msg="[detect] code: 0, message: ok, item: dns" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:12+08:00" level=info msg="[task]Detect item: disk-size root" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:12+08:00" level=info msg="[detect] code: 0, message: ok, item: disk-size root" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:12+08:00" level=info msg="[task]Detect item: disk-size cache" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:13+08:00" level=info msg="[detect] code: 0, message: ok, item: disk-size cache" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:18+08:00" level=warning msg="report event DetectFinish failed: send training-event info to algorancher failed, err: Post \"https://modelarts.cn-east-321.nbaicc.com/v2/17c194e82d5f4ec68a451515b77a1b5b/training-jobs/2c4fde60-364b-472d-a00f-922d0618e076/tasks/worker-0/reports/training-event\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" file="event.go:51" Command=report Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:55:18+08:00" level=info msg="[init] autosearch_path is empty, skip the autosearch download" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:18+08:00" level=info msg="[init] code_url is empty, skip the code download." Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:18+08:00" level=info msg="[init] record_dir is empty, skip the code upload" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:18+08:00" level=info msg="[init] inputs_handler_job_pid = 261" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:19+08:00" level=info msg="env MA_INPUTS is empty, skip the inputs handler" Component=PythonScripts Platform=ModelArts-Service
time="2023-10-13T10:55:20+08:00" level=info msg="[init] exiting at 2023-10-13-10:55:20" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:20+08:00" level=info msg="[init] upload_metrics_pid = 404" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:37+08:00" level=info msg="[init] stop toolkit_obs_upload_pid = 56 by signal SIGTERM" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:37+08:00" level=info msg="the periodic upload task exiting..." file="upload.go:216" Command=obs/upload Component=ma-training-toolkit Platform=ModelArts-Service Task=
time="2023-10-13T10:55:53+08:00" level=info msg="[init] toolkit_obs_upload 56 ret_code is 0" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:53+08:00" level=info msg="[init] exit with 0" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:55:53+08:00" level=info msg="local dir = /home/ma-user/modelarts/log/" file="upload.go:193" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service Task=
time="2023-10-13T10:55:53+08:00" level=info msg="obs dir = s3://modelarts-training-log-cneast321/2c4fde60-364b-472d-a00f-922d0618e076/worker-0" file="upload.go:196" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service Task=
time="2023-10-13T10:56:31+08:00" level=warning msg="report event InitExit failed: send training-event info to algorancher failed, err: Post \"https://modelarts.cn-east-321.nbaicc.com/v2/17c194e82d5f4ec68a451515b77a1b5b/training-jobs/2c4fde60-364b-472d-a00f-922d0618e076/tasks/worker-0/reports/training-event\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" file="event.go:51" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:31+08:00" level=info msg="bootstrap is exiting with exit code 0" file="bootstrap.go:241" Command=bootstrap/init Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:32+08:00" level=info msg="init logger successful" file="run_train.go:86" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:32+08:00" level=info msg="Waiting for SCC server start." file="run_train.go:439" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:32+08:00" level=info msg="init logger successful" file="upload.go:39" Command=bootstrap/upload Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:32+08:00" level=info msg="current user 1000:1000" file="upload.go:41" Command=bootstrap/upload Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="Call SCC server API err: Post \"http://127.0.0.1:39521/health\": dial tcp 127.0.0.1:39521: connect: connection refused, current retry: 1." file="run_train.go:461" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=warning msg="report event SidecarStart failed: send training-event info to algorancher failed, err: Post \"https://modelarts.cn-east-321.nbaicc.com/v2/17c194e82d5f4ec68a451515b77a1b5b/training-jobs/2c4fde60-364b-472d-a00f-922d0618e076/tasks/worker-0/reports/training-event\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" file="event.go:51" Command=bootstrap/upload Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="upload command: /home/ma-user/training/sidecar.sh" file="upload.go:57" Command=bootstrap/upload Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="scc is already installed, skipping this step..." Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="[sidecar] running at 2023-10-13-10:56:37" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="[sidecar] scc server pid = 51" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="[sidecar] toolkit_obs_upload_by_channels_pid = 53" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="[sidecar] waiting for training complete" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="MA_OUTPUTS environment variable is empty, skip creating upload tasks." file="upload_by_channels.go:52" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:37+08:00" level=info msg="Starting SCC server on 127.0.0.1:39521" file="server.go:53" Command=scc-server Component=ma-scc-server Platform=ModelArts-Service
time="2023-10-13T10:56:42+08:00" level=info msg="SCC server has been init, training continue." file="run_train.go:457" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=warning msg="report event TrainingStart failed: send training-event info to algorancher failed, err: Post \"https://modelarts.cn-east-321.nbaicc.com/v2/17c194e82d5f4ec68a451515b77a1b5b/training-jobs/2c4fde60-364b-472d-a00f-922d0618e076/tasks/worker-0/reports/training-event\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" file="event.go:51" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=info msg="Skip hang detect" file="run_train.go:474" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=info msg="pre train command: /modelarts-job-2c4fde60-364b-472d-a00f-922d0618e076/ma-training-toolkit detect image-check; mkdir -p ~/.pip; echo -e '[global]\\ntrusted-host = pip.modelarts.private.com\\nindex-url = http://pip.modelarts.private.com:8888/repository/pypi/simple' > ~/.pip/pip.conf;  " file="run_train.go:510" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=info msg="runUser name: ma-user" file="image_check.go:54" Command=image-check Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=info msg="runUser uid: 1000" file="image_check.go:55" Command=image-check Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=info msg="runUser gid: 100" file="image_check.go:56" Command=image-check Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=info msg="run command: mkdir -p /cache/code;mkdir -p /cache/pretrainmodel;mkdir -p /cache/dataset;mkdir -p /cache/output;export bucket=PROD && export remote_path=job/liwk20231013106t51511998/output/;echo 'start to exec code';source /home/ma-user/.bashrc;export GLOG_v=3;export ASCEND_GLOBAL_LOG_LEVEL=3;export ASCEND_SLOG_PRINT_TO_STDOUT=0 ;export HCCL_CONNECT_TIMEOUT=3600;export HCCL_EXEC_TIMEOUT=1800;export PIPELINE_SLICE_SKIP_REDISTRIBUTION=1;export MS_DEV_REDUNDANCY_TASK_NUM=4;export MS_DEV_CELL_REUSE=2;python /home/ma-user/davinci/train/davincirun.py python /home/ma-user/grampus.py  --'rank_size'='1' --multi_data_url='[{\"dataset_url\":\"s3:///urchincache/attachment/8/1/81cd7def-5d35-46cc-b440-3a506446e51c/NYC_RISK.zip\",\"dataset_name\":\"NYC_RISK.zip\",\"containerPath\":\"/cache/dataset/NYC_RISK.zip\",\"readOnly\":true}]' --pretrain_url='[]' --code_url='s3:///urchincache/job/liwk20231013106t51511998/code/master.zip' --code_name='m-libcity' --boot_file='M_libcity/test_pipeline.py' --model_url='s3:///grampus/job/liwk20231013106t51511998/output/' --grampus_code_url='s3:///grampus/system_code/' --grampus_code_file_name='pre_and_suf.py';result=$?;bash -c \"[[ $result -eq 0 ]] && exit 0 || exit -1\"; " file="run_train.go:322" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T10:56:47+08:00" level=info msg="zombie process cleaner is start running, childPid=31" file="cleaner_unix.go:31" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
start to exec code
sh: /modelarts/authoring/script/entrypoint/common/terminal_tips.sh: No such file or directory
INFO:root:Using MoXing-v2.1.7.dc1f3d0b-dc1f3d0b
INFO:root:Using OBS-Python-SDK-3.20.9.1
[ModelArts Service Log]2023-10-13 10:56:48,596 - INFO - Ascend Driver: Version=22.0.0.3
[ModelArts Service Log]2023-10-13 10:56:48,596 - INFO - you are advised to use ASCEND_DEVICE_ID env instead of DEVICE_ID, as the DEVICE_ID env will be discarded in later versions
[ModelArts Service Log]2023-10-13 10:56:48,596 - INFO - particularly, ${ASCEND_DEVICE_ID} == ${DEVICE_ID}, it's the logical device id
[ModelArts Service Log]2023-10-13 10:56:48,596 - INFO - Davinci training command
[ModelArts Service Log]2023-10-13 10:56:48,596 - INFO - ['python', '/home/ma-user/grampus.py', '--rank_size=1', '--multi_data_url=[{"dataset_url":"s3:///urchincache/attachment/8/1/81cd7def-5d35-46cc-b440-3a506446e51c/NYC_RISK.zip","dataset_name":"NYC_RISK.zip","containerPath":"/cache/dataset/NYC_RISK.zip","readOnly":true}]', '--pretrain_url=[]', '--code_url=s3:///urchincache/job/liwk20231013106t51511998/code/master.zip', '--code_name=m-libcity', '--boot_file=M_libcity/test_pipeline.py', '--model_url=s3:///grampus/job/liwk20231013106t51511998/output/', '--grampus_code_url=s3:///grampus/system_code/', '--grampus_code_file_name=pre_and_suf.py']
[ModelArts Service Log]2023-10-13 10:56:48,597 - INFO - Wait for Rank table file ready
[ModelArts Service Log]2023-10-13 10:56:48,597 - INFO - Rank table file (K8S generated) is ready for read
[ModelArts Service Log]2023-10-13 10:56:48,597 - INFO - 
{
    "status": "completed",
    "group_count": "1",
    "group_list": [
        {
            "group_name": "worker",
            "device_count": "1",
            "instance_count": "1",
            "instance_list": [
                {
                    "pod_name": "ma-job-2c4fde60-364b-472d-a00f-922d0618e076-worker-0",
                    "server_id": "192.168.12.241",
                    "devices": [
                        {
                            "device_id": "1",
                            "device_ip": "192.2.147.97"
                        }
                    ]
                }
            ]
        }
    ]
}
[ModelArts Service Log]2023-10-13 10:56:48,597 - INFO - Rank table file (V1)
[ModelArts Service Log]2023-10-13 10:56:48,598 - INFO - 
{
    "status": "completed",
    "version": "1.0",
    "server_count": "1",
    "server_list": [
        {
            "server_id": "192.168.12.241",
            "device": [
                {
                    "device_id": "1",
                    "device_ip": "192.2.147.97",
                    "rank_id": "0"
                }
            ]
        }
    ]
}
[ModelArts Service Log]2023-10-13 10:56:48,598 - INFO - Rank table file (V1) is generated
[ModelArts Service Log]2023-10-13 10:56:48,598 - INFO - Current server
[ModelArts Service Log]2023-10-13 10:56:48,599 - INFO - 
{
    "server_id": "192.168.12.241",
    "device": [
        {
            "device_id": "1",
            "device_ip": "192.2.147.97",
            "rank_id": "0"
        }
    ]
}
[ModelArts Service Log]2023-10-13 10:56:48,599 - INFO - Route plan ends for env ROUTE_PLAN = false. Route plan acceleration service may not be available in this region
[ModelArts Service Log]2023-10-13 10:56:48,600 - INFO - env already exists. env_name: HCCL_CONNECT_TIMEOUT, env_value: 1800 
[ModelArts Service Log]2023-10-13 10:56:48,600 - INFO - bootstrap proc-rank-0-device-0
[ModelArts Service Log]2023-10-13 10:56:48,609 - INFO - proc-rank-0-device-0 (pid: 129)
time="2023-10-13T10:56:54+08:00" level=info msg="local dir = /home/ma-user/modelarts/log/" file="upload.go:193" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=srt_log_collection
time="2023-10-13T10:56:54+08:00" level=info msg="obs dir = s3://modelarts-training-log-cneast321/2c4fde60-364b-472d-a00f-922d0618e076/worker-0" file="upload.go:196" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=srt_log_collection
time="2023-10-13T10:56:54+08:00" level=info msg="start the periodic upload task, upload Period = 5 seconds " file="upload.go:206" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=srt_log_collection
time="2023-10-13T10:56:54+08:00" level=info msg="local dir = /home/ma-user/modelarts/log/" file="upload.go:193" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=log_url
time="2023-10-13T10:56:54+08:00" level=info msg="obs dir = obs://grampus/log/" file="upload.go:196" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=log_url
time="2023-10-13T10:56:54+08:00" level=info msg="start the periodic upload task, upload Period = 30 seconds " file="upload.go:206" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=log_url
INFO:root:List OBS time cost: 0.01 seconds.
INFO:root:Copy parallel total time cost: 1.17 seconds.
INFO:root:Log directory: /cache/code/m-libcity/M_libcity/log
Successfully Download /cache/code/m-libcity/M_libcity/data/ to /cache/code/m-libcity/M_libcity/raw_data
download_input succeed
2023-10-13 10:57:39,861 - INFO - Log directory: /cache/code/m-libcity/M_libcity/log
INFO:root:Begin pipeline, task=traffic_state_pred, model_name=DCRNN, dataset_name=NYCBike20140409, exp_id=7064
2023-10-13 10:57:39,862 - INFO - Begin pipeline, task=traffic_state_pred, model_name=DCRNN, dataset_name=NYCBike20140409, exp_id=7064
INFO:root:{'task': 'traffic_state_pred', 'model': 'DCRNN', 'dataset': 'NYCBike20140409', 'saved_model': True, 'train': True, 'rank_size': 1, 'batch_size': 64, 'max_epoch': 30, 'dataset_class': 'TrafficStateGridDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'bidir_adj_mx': False, 'max_diffusion_step': 2, 'num_rnn_layers': 2, 'rnn_units': 32, 'use_curriculum_learning': True, 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': True, 'add_day_in_week': False, 'learner': 'adam', 'learning_rate': 0.01, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'cache_dataset': True, 'num_workers': 1, 'pad_with_last_sample': True, 'train_rate': 0.8, 'eval_rate': 0.1, 'input_window': 12, 'output_window': 12, 'use_row_column': False, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0.0, 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Polygon'], 'Polygon': {'row_id': 'num', 'column_id': 'num'}}, 'grid': {'including_types': ['state'], 'state': {'row_id': 16, 'column_id': 8, 'new_flow': 'num', 'end_flow': 'num'}}, 'data_col': ['new_flow', 'end_flow'], 'data_files': ['NYCBIKE20140409'], 'geo_file': 'NYCBIKE20140409', 'output_dim': 2, 'time_intervals': 3600, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'exp_id': 7064}
2023-10-13 10:57:39,862 - INFO - {'task': 'traffic_state_pred', 'model': 'DCRNN', 'dataset': 'NYCBike20140409', 'saved_model': True, 'train': True, 'rank_size': 1, 'batch_size': 64, 'max_epoch': 30, 'dataset_class': 'TrafficStateGridDataset', 'executor': 'TrafficStateExecutor', 'evaluator': 'TrafficStateEvaluator', 'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'bidir_adj_mx': False, 'max_diffusion_step': 2, 'num_rnn_layers': 2, 'rnn_units': 32, 'use_curriculum_learning': True, 'scaler': 'standard', 'load_external': True, 'normal_external': False, 'ext_scaler': 'none', 'add_time_in_day': True, 'add_day_in_week': False, 'learner': 'adam', 'learning_rate': 0.01, 'lr_decay': False, 'lr_scheduler': 'multisteplr', 'lr_decay_ratio': 0.1, 'steps': [5, 20, 40, 70], 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 50, 'cache_dataset': True, 'num_workers': 1, 'pad_with_last_sample': True, 'train_rate': 0.8, 'eval_rate': 0.1, 'input_window': 12, 'output_window': 12, 'use_row_column': False, 'gpu': True, 'gpu_id': 0, 'train_loss': 'none', 'epoch': 0, 'weight_decay': 0, 'lr_epsilon': 1e-08, 'lr_beta1': 0.9, 'lr_beta2': 0.999, 'lr_alpha': 0.99, 'lr_momentum': 0.0, 'step_size': 10, 'lr_T_max': 30, 'lr_eta_min': 0, 'lr_patience': 10, 'lr_threshold': 0.0001, 'log_level': 'INFO', 'log_every': 1, 'load_best_epoch': True, 'hyper_tune': False, 'metrics': ['MAE', 'MAPE', 'MSE', 'RMSE', 'masked_MAE', 'masked_MAPE', 'masked_MSE', 'masked_RMSE'], 'evaluator_mode': 'single', 'save_mode': ['csv'], 'geo': {'including_types': ['Polygon'], 'Polygon': {'row_id': 'num', 'column_id': 'num'}}, 'grid': {'including_types': ['state'], 'state': {'row_id': 16, 'column_id': 8, 'new_flow': 'num', 'end_flow': 'num'}}, 'data_col': ['new_flow', 'end_flow'], 'data_files': ['NYCBIKE20140409'], 'geo_file': 'NYCBIKE20140409', 'output_dim': 2, 'time_intervals': 3600, 'init_weight_inf_or_zero': 'inf', 'set_weight_link_or_dist': 'dist', 'calculate_weight_adj': False, 'weight_adj_epsilon': 0.1, 'exp_id': 7064}
INFO:root:Loaded file NYCBIKE20140409.geo, num_grids=128, grid_size=(16, 8)
2023-10-13 10:57:39,904 - INFO - Loaded file NYCBIKE20140409.geo, num_grids=128, grid_size=(16, 8)
INFO:root:Generate grid rel file, shape=(128, 128)
2023-10-13 10:57:39,906 - INFO - Generate grid rel file, shape=(128, 128)
INFO:root:Loading file NYCBIKE20140409.grid
2023-10-13 10:57:39,906 - INFO - Loading file NYCBIKE20140409.grid
INFO:root:Loaded file NYCBIKE20140409.grid, shape=(4392, 128, 2)
2023-10-13 10:57:40,658 - INFO - Loaded file NYCBIKE20140409.grid, shape=(4392, 128, 2)
INFO:root:Dataset created
2023-10-13 10:57:41,325 - INFO - Dataset created
INFO:root:x shape: (4369, 12, 128, 3), y shape: (4369, 12, 128, 3)
2023-10-13 10:57:41,326 - INFO - x shape: (4369, 12, 128, 3), y shape: (4369, 12, 128, 3)
INFO:root:train	x: (3495, 12, 128, 3), y: (3495, 12, 128, 3)
2023-10-13 10:57:41,328 - INFO - train	x: (3495, 12, 128, 3), y: (3495, 12, 128, 3)
INFO:root:eval	x: (437, 12, 128, 3), y: (437, 12, 128, 3)
2023-10-13 10:57:41,328 - INFO - eval	x: (437, 12, 128, 3), y: (437, 12, 128, 3)
INFO:root:test	x: (437, 12, 128, 3), y: (437, 12, 128, 3)
2023-10-13 10:57:41,329 - INFO - test	x: (437, 12, 128, 3), y: (437, 12, 128, 3)
INFO:root:Saved at /cache/code/m-libcity/M_libcity/cache/dataset_cache/grid_based_NYCBike20140409_12_12_0.8_0.1_standard_64_True_True_False_True_False.npz
2023-10-13 10:57:51,889 - INFO - Saved at /cache/code/m-libcity/M_libcity/cache/dataset_cache/grid_based_NYCBike20140409_12_12_0.8_0.1_standard_64_True_True_False_True_False.npz
INFO:root:StandardScaler mean: 9.371765561665475, std: 18.27140197139823
!!! 3 1 2
2023-10-13 10:57:52,351 - INFO - StandardScaler mean: 9.371765561665475, std: 18.27140197139823
INFO:root:NoneScaler
2023-10-13 10:57:52,351 - INFO - NoneScaler
[INFO] PARALLEL(366,ffff9966fa40,python):2023-10-13-10:57:57.768.564 [mindspore/ccsrc/frontend/parallel/costmodel_context.cc:30] GetInstance] Create costmodel_context
[INFO] CORE(366,ffff9966fa40,python):2023-10-13-10:57:57.822.379 [mindspore/core/utils/ms_context.h:242] set_param_inner<std::basic_string<char> >] ms set context device target:Ascend
[INFO] CORE(366,ffff9966fa40,python):2023-10-13-10:57:58.098.081 [mindspore/core/utils/ms_context.cc:150] set_backend_policy] ms set context backend policy:ms
[INFO] ME(366:281473255406144,MainProcess):2023-10-13-10:58:02.188.605 [mindspore/_extends/remote/kernel_build_server_ascend.py:32] [TRACE] Ascend Messager init...
INFO:root:DCRNN<
  (network): DCRNNModel<
    (encoder_model): EncoderModel<
      (dcgru_layers): CellList<
        (0): DCGRUCell<>
        (1): DCGRUCell<>
        >
      >
    (decoder_model): DecoderModel<
      (projection_layer): Dense<input_channels=32, output_channels=1, has_bias=True>
      (dcgru_layers): CellList<
        (0): DCGRUCell<>
        (1): DCGRUCell<>
        >
      >
    >
  >
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!data/utils
{'cl_decay_steps': 2000, 'filter_type': 'dual_random_walk', 'horizon': 12, 'input_dim': 3, 'l1_decay': 0, 'max_diffusion_step': 2, 'num_nodes': 128, 'num_rnn_layers': 2, 'output_dim': 1, 'rnn_units': 32, 'seq_len': 12, 'use_curriculum_learning': True}
(12, 32, 256)
new weight: (170, 64)
new bias: 64
new weight: (170, 32)
new bias: 32
new weight: (320, 64)
new bias: 64
new weight: (320, 32)
new bias: 32
new weight: (165, 64)
new bias: 64
new weight: (165, 32)
new bias: 32
new weight: (320, 64)
new bias: 64
new weight: (320, 32)
new bias: 32
2023-10-13 11:01:02,174 - INFO - DCRNN<
  (network): DCRNNModel<
    (encoder_model): EncoderModel<
      (dcgru_layers): CellList<
        (0): DCGRUCell<>
        (1): DCGRUCell<>
        >
      >
    (decoder_model): DecoderModel<
      (projection_layer): Dense<input_channels=32, output_channels=1, has_bias=True>
      (dcgru_layers): CellList<
        (0): DCGRUCell<>
        (1): DCGRUCell<>
        >
      >
    >
  >
INFO:root:gconv_weight_(170, 64)_1	(170, 64)	True
2023-10-13 11:01:02,176 - INFO - gconv_weight_(170, 64)_1	(170, 64)	True
INFO:root:gconv_biases_64_1	(64,)	True
2023-10-13 11:01:02,176 - INFO - gconv_biases_64_1	(64,)	True
INFO:root:gconv_weight_(170, 32)_2	(170, 32)	True
2023-10-13 11:01:02,176 - INFO - gconv_weight_(170, 32)_2	(170, 32)	True
INFO:root:gconv_biases_32_2	(32,)	True
2023-10-13 11:01:02,176 - INFO - gconv_biases_32_2	(32,)	True
INFO:root:gconv_weight_(320, 64)_3	(320, 64)	True
2023-10-13 11:01:02,176 - INFO - gconv_weight_(320, 64)_3	(320, 64)	True
INFO:root:gconv_biases_64_3	(64,)	True
2023-10-13 11:01:02,177 - INFO - gconv_biases_64_3	(64,)	True
INFO:root:gconv_weight_(320, 32)_4	(320, 32)	True
2023-10-13 11:01:02,177 - INFO - gconv_weight_(320, 32)_4	(320, 32)	True
INFO:root:gconv_biases_32_4	(32,)	True
2023-10-13 11:01:02,177 - INFO - gconv_biases_32_4	(32,)	True
INFO:root:network.decoder_model.projection_layer.weight	(1, 32)	True
2023-10-13 11:01:02,177 - INFO - network.decoder_model.projection_layer.weight	(1, 32)	True
INFO:root:network.decoder_model.projection_layer.bias	(1,)	True
2023-10-13 11:01:02,177 - INFO - network.decoder_model.projection_layer.bias	(1,)	True
INFO:root:gconv_weight_(165, 64)_5	(165, 64)	True
2023-10-13 11:01:02,177 - INFO - gconv_weight_(165, 64)_5	(165, 64)	True
INFO:root:gconv_biases_64_5	(64,)	True
2023-10-13 11:01:02,177 - INFO - gconv_biases_64_5	(64,)	True
INFO:root:gconv_weight_(165, 32)_6	(165, 32)	True
2023-10-13 11:01:02,178 - INFO - gconv_weight_(165, 32)_6	(165, 32)	True
INFO:root:gconv_biases_32_6	(32,)	True
2023-10-13 11:01:02,178 - INFO - gconv_biases_32_6	(32,)	True
INFO:root:gconv_weight_(320, 64)_7	(320, 64)	True
2023-10-13 11:01:02,178 - INFO - gconv_weight_(320, 64)_7	(320, 64)	True
INFO:root:gconv_biases_64_7	(64,)	True
2023-10-13 11:01:02,178 - INFO - gconv_biases_64_7	(64,)	True
INFO:root:gconv_weight_(320, 32)_8	(320, 32)	True
2023-10-13 11:01:02,178 - INFO - gconv_weight_(320, 32)_8	(320, 32)	True
INFO:root:gconv_biases_32_8	(32,)	True
2023-10-13 11:01:02,178 - INFO - gconv_biases_32_8	(32,)	True
INFO:root:Total parameter numbers: 94017
2023-10-13 11:01:02,179 - INFO - Total parameter numbers: 94017
INFO:root:You select `adam` optimizer.
2023-10-13 11:01:02,179 - INFO - You select `adam` optimizer.
WARNING:root:Received none train loss func and will use the loss func defined in the model.
2023-10-13 11:01:02,282 - WARNING - Received none train loss func and will use the loss func defined in the model.
INFO:root:Start training ...
2023-10-13 11:01:02,283 - INFO - Start training ...
INFO:root:num_batches:54
2023-10-13 11:01:02,283 - INFO - num_batches:54
new weight: (175, 64)
new weight: (175, 32)
epoch: 1 step: 1, loss is 15.03803825378418
epoch: 1 step: 2, loss is 13.054678916931152
epoch: 1 step: 3, loss is 14.18500804901123
epoch: 1 step: 4, loss is 13.584794044494629
epoch: 1 step: 5, loss is 12.284180641174316
epoch: 1 step: 6, loss is 11.337315559387207
epoch: 1 step: 7, loss is 10.2069673538208
epoch: 1 step: 8, loss is 11.040911674499512
epoch: 1 step: 9, loss is 9.035093307495117
epoch: 1 step: 10, loss is 9.268391609191895
epoch: 1 step: 11, loss is 9.021784782409668
epoch: 1 step: 12, loss is 8.2676420211792
epoch: 1 step: 13, loss is 8.055636405944824
epoch: 1 step: 14, loss is 8.230494499206543
epoch: 1 step: 15, loss is 7.577332496643066
epoch: 1 step: 16, loss is 7.592795372009277
epoch: 1 step: 17, loss is 7.515983581542969
epoch: 1 step: 18, loss is 7.151701927185059
epoch: 1 step: 19, loss is 7.334301948547363
epoch: 1 step: 20, loss is 6.6478729248046875
epoch: 1 step: 21, loss is 6.930576801300049
epoch: 1 step: 22, loss is 6.538516044616699
epoch: 1 step: 23, loss is 6.144612789154053
epoch: 1 step: 24, loss is 6.401533126831055
epoch: 1 step: 25, loss is 5.912136554718018
epoch: 1 step: 26, loss is 6.4798407554626465
epoch: 1 step: 27, loss is 5.949714660644531
epoch: 1 step: 28, loss is 6.052253246307373
epoch: 1 step: 29, loss is 5.91000509262085
epoch: 1 step: 30, loss is 5.8874735832214355
epoch: 1 step: 31, loss is 6.1583709716796875
epoch: 1 step: 32, loss is 5.771151542663574
epoch: 1 step: 33, loss is 5.642995834350586
epoch: 1 step: 34, loss is 5.734140396118164
epoch: 1 step: 35, loss is 5.988101005554199
epoch: 1 step: 36, loss is 5.9393110275268555
epoch: 1 step: 37, loss is 5.5064849853515625
epoch: 1 step: 38, loss is 5.97672700881958
epoch: 1 step: 39, loss is 5.331541061401367
epoch: 1 step: 40, loss is 5.740702152252197
epoch: 1 step: 41, loss is 5.510324001312256
epoch: 1 step: 42, loss is 5.5986647605896
epoch: 1 step: 43, loss is 5.599959850311279
epoch: 1 step: 44, loss is 5.688863754272461
epoch: 1 step: 45, loss is 5.550044536590576
epoch: 1 step: 46, loss is 5.560898303985596
epoch: 1 step: 47, loss is 5.529938220977783
epoch: 1 step: 48, loss is 5.357329368591309
epoch: 1 step: 49, loss is 5.364874362945557
epoch: 1 step: 50, loss is 5.345217704772949
epoch: 1 step: 51, loss is 5.3477020263671875
epoch: 1 step: 52, loss is 5.485712051391602
epoch: 1 step: 53, loss is 5.341773509979248
epoch: 1 step: 54, loss is 5.4496378898620605
Train epoch time: 1517818.524 ms, per step time: 28107.750 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 11:26:20,110 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.462968349456787
2023-10-13 11:26:33,889 - INFO - valid loss 为: 5.462968349456787
epoch: 2 step: 1, loss is 5.479793548583984
epoch: 2 step: 2, loss is 5.1624956130981445
epoch: 2 step: 3, loss is 5.297472953796387
epoch: 2 step: 4, loss is 4.8832011222839355
epoch: 2 step: 5, loss is 5.3978681564331055
epoch: 2 step: 6, loss is 4.964657306671143
epoch: 2 step: 7, loss is 5.2509002685546875
epoch: 2 step: 8, loss is 4.992788314819336
epoch: 2 step: 9, loss is 4.860198020935059
epoch: 2 step: 10, loss is 5.203470230102539
epoch: 2 step: 11, loss is 5.2508697509765625
epoch: 2 step: 12, loss is 5.049037933349609
epoch: 2 step: 13, loss is 5.195810794830322
epoch: 2 step: 14, loss is 5.374955177307129
epoch: 2 step: 15, loss is 4.882919788360596
epoch: 2 step: 16, loss is 5.097802639007568
epoch: 2 step: 17, loss is 5.222390174865723
epoch: 2 step: 18, loss is 5.319206714630127
epoch: 2 step: 19, loss is 5.494922161102295
epoch: 2 step: 20, loss is 4.997765064239502
epoch: 2 step: 21, loss is 5.126582145690918
epoch: 2 step: 22, loss is 5.040467262268066
epoch: 2 step: 23, loss is 5.092914581298828
epoch: 2 step: 24, loss is 5.112596035003662
epoch: 2 step: 25, loss is 5.436036109924316
epoch: 2 step: 26, loss is 4.915376663208008
epoch: 2 step: 27, loss is 5.001359939575195
epoch: 2 step: 28, loss is 4.883213996887207
epoch: 2 step: 29, loss is 5.004286289215088
epoch: 2 step: 30, loss is 4.944786548614502
epoch: 2 step: 31, loss is 5.017993450164795
epoch: 2 step: 32, loss is 4.983396053314209
epoch: 2 step: 33, loss is 4.970541954040527
epoch: 2 step: 34, loss is 4.855538845062256
epoch: 2 step: 35, loss is 4.780254364013672
epoch: 2 step: 36, loss is 4.871816635131836
epoch: 2 step: 37, loss is 4.914430141448975
epoch: 2 step: 38, loss is 4.96180534362793
epoch: 2 step: 39, loss is 4.618693828582764
epoch: 2 step: 40, loss is 4.880857944488525
epoch: 2 step: 41, loss is 4.801681995391846
epoch: 2 step: 42, loss is 4.615109443664551
epoch: 2 step: 43, loss is 4.820913791656494
epoch: 2 step: 44, loss is 4.9571943283081055
epoch: 2 step: 45, loss is 4.959730625152588
epoch: 2 step: 46, loss is 4.891118049621582
epoch: 2 step: 47, loss is 4.947147846221924
epoch: 2 step: 48, loss is 4.571357250213623
epoch: 2 step: 49, loss is 4.645742893218994
epoch: 2 step: 50, loss is 4.639759063720703
epoch: 2 step: 51, loss is 4.841558933258057
epoch: 2 step: 52, loss is 4.511862277984619
epoch: 2 step: 53, loss is 4.922243118286133
epoch: 2 step: 54, loss is 4.771628379821777
Train epoch time: 510304.250 ms, per step time: 9450.079 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 11:35:04,199 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.905594348907471
2023-10-13 11:35:16,415 - INFO - valid loss 为: 4.905594348907471
epoch: 3 step: 1, loss is 4.635036468505859
epoch: 3 step: 2, loss is 4.895956993103027
epoch: 3 step: 3, loss is 4.856537342071533
epoch: 3 step: 4, loss is 4.585022449493408
epoch: 3 step: 5, loss is 4.762844562530518
epoch: 3 step: 6, loss is 5.007436275482178
epoch: 3 step: 7, loss is 4.541545391082764
epoch: 3 step: 8, loss is 4.932795524597168
epoch: 3 step: 9, loss is 4.86420202255249
epoch: 3 step: 10, loss is 4.870469570159912
epoch: 3 step: 11, loss is 4.759551525115967
epoch: 3 step: 12, loss is 5.0919623374938965
epoch: 3 step: 13, loss is 4.9013872146606445
epoch: 3 step: 14, loss is 4.967053413391113
epoch: 3 step: 15, loss is 4.8035888671875
epoch: 3 step: 16, loss is 4.5868353843688965
epoch: 3 step: 17, loss is 4.8749823570251465
epoch: 3 step: 18, loss is 4.664307117462158
epoch: 3 step: 19, loss is 4.567309379577637
epoch: 3 step: 20, loss is 4.872109413146973
epoch: 3 step: 21, loss is 4.739348411560059
epoch: 3 step: 22, loss is 4.494777679443359
epoch: 3 step: 23, loss is 4.65389347076416
epoch: 3 step: 24, loss is 4.343017578125
epoch: 3 step: 25, loss is 4.7831854820251465
epoch: 3 step: 26, loss is 4.7064690589904785
epoch: 3 step: 27, loss is 4.871814727783203
epoch: 3 step: 28, loss is 4.41048526763916
epoch: 3 step: 29, loss is 4.7171244621276855
epoch: 3 step: 30, loss is 4.765470027923584
epoch: 3 step: 31, loss is 4.6241230964660645
epoch: 3 step: 32, loss is 4.45688533782959
epoch: 3 step: 33, loss is 4.76861047744751
epoch: 3 step: 34, loss is 4.693151473999023
epoch: 3 step: 35, loss is 4.595787048339844
epoch: 3 step: 36, loss is 4.297421932220459
epoch: 3 step: 37, loss is 4.500430107116699
epoch: 3 step: 38, loss is 4.546727657318115
epoch: 3 step: 39, loss is 4.447619915008545
epoch: 3 step: 40, loss is 4.779857635498047
epoch: 3 step: 41, loss is 4.763576984405518
epoch: 3 step: 42, loss is 4.817470550537109
epoch: 3 step: 43, loss is 4.941214561462402
epoch: 3 step: 44, loss is 5.000876426696777
epoch: 3 step: 45, loss is 4.784114360809326
epoch: 3 step: 46, loss is 4.6587066650390625
epoch: 3 step: 47, loss is 4.903957843780518
epoch: 3 step: 48, loss is 4.965510368347168
epoch: 3 step: 49, loss is 4.475197792053223
epoch: 3 step: 50, loss is 4.621903896331787
epoch: 3 step: 51, loss is 4.969865322113037
epoch: 3 step: 52, loss is 4.742047309875488
epoch: 3 step: 53, loss is 4.495260715484619
epoch: 3 step: 54, loss is 4.497832298278809
Train epoch time: 531323.930 ms, per step time: 9839.332 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 11:44:07,743 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.678223609924316
2023-10-13 11:44:20,322 - INFO - valid loss 为: 4.678223609924316
epoch: 4 step: 1, loss is 4.701048851013184
epoch: 4 step: 2, loss is 4.69868278503418
epoch: 4 step: 3, loss is 4.515124320983887
epoch: 4 step: 4, loss is 4.684978485107422
epoch: 4 step: 5, loss is 4.814529895782471
epoch: 4 step: 6, loss is 4.677866458892822
epoch: 4 step: 7, loss is 4.5350236892700195
epoch: 4 step: 8, loss is 4.626651763916016
epoch: 4 step: 9, loss is 4.733883380889893
epoch: 4 step: 10, loss is 4.559934139251709
epoch: 4 step: 11, loss is 4.4967265129089355
epoch: 4 step: 12, loss is 4.73153018951416
epoch: 4 step: 13, loss is 4.691709995269775
epoch: 4 step: 14, loss is 4.732394218444824
epoch: 4 step: 15, loss is 4.665283203125
epoch: 4 step: 16, loss is 4.396560192108154
epoch: 4 step: 17, loss is 4.629979133605957
epoch: 4 step: 18, loss is 4.594789505004883
epoch: 4 step: 19, loss is 4.630284309387207
epoch: 4 step: 20, loss is 4.41518497467041
epoch: 4 step: 21, loss is 4.707668304443359
epoch: 4 step: 22, loss is 4.7266364097595215
epoch: 4 step: 23, loss is 4.7703094482421875
epoch: 4 step: 24, loss is 4.600190162658691
epoch: 4 step: 25, loss is 4.656083583831787
epoch: 4 step: 26, loss is 4.608989238739014
epoch: 4 step: 27, loss is 4.484835147857666
epoch: 4 step: 28, loss is 4.440996170043945
epoch: 4 step: 29, loss is 4.534084796905518
epoch: 4 step: 30, loss is 4.356626510620117
epoch: 4 step: 31, loss is 4.514444351196289
epoch: 4 step: 32, loss is 4.580573081970215
epoch: 4 step: 33, loss is 4.6392502784729
epoch: 4 step: 34, loss is 4.241380214691162
epoch: 4 step: 35, loss is 4.305793285369873
epoch: 4 step: 36, loss is 4.205787658691406
epoch: 4 step: 37, loss is 4.391674518585205
epoch: 4 step: 38, loss is 4.799103736877441
epoch: 4 step: 39, loss is 4.492777347564697
epoch: 4 step: 40, loss is 4.2907280921936035
epoch: 4 step: 41, loss is 4.5149712562561035
epoch: 4 step: 42, loss is 4.452288627624512
epoch: 4 step: 43, loss is 4.474587917327881
epoch: 4 step: 44, loss is 4.519680023193359
epoch: 4 step: 45, loss is 4.5578155517578125
epoch: 4 step: 46, loss is 4.357501029968262
epoch: 4 step: 47, loss is 4.427417278289795
epoch: 4 step: 48, loss is 4.631608486175537
epoch: 4 step: 49, loss is 4.5266289710998535
epoch: 4 step: 50, loss is 4.449469089508057
epoch: 4 step: 51, loss is 4.747405529022217
epoch: 4 step: 52, loss is 4.663302898406982
epoch: 4 step: 53, loss is 4.718382358551025
epoch: 4 step: 54, loss is 4.401736736297607
Train epoch time: 615867.255 ms, per step time: 11404.949 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 11:54:36,191 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.630277633666992
2023-10-13 11:54:48,348 - INFO - valid loss 为: 4.630277633666992
epoch: 5 step: 1, loss is 4.415189743041992
epoch: 5 step: 2, loss is 4.592421531677246
epoch: 5 step: 3, loss is 4.424306392669678
epoch: 5 step: 4, loss is 4.572028636932373
epoch: 5 step: 5, loss is 4.604753017425537
epoch: 5 step: 6, loss is 4.5454583168029785
epoch: 5 step: 7, loss is 4.748663902282715
epoch: 5 step: 8, loss is 4.504818916320801
epoch: 5 step: 9, loss is 4.594111442565918
epoch: 5 step: 10, loss is 4.48167610168457
epoch: 5 step: 11, loss is 4.371901035308838
epoch: 5 step: 12, loss is 4.421074867248535
epoch: 5 step: 13, loss is 4.498225688934326
epoch: 5 step: 14, loss is 4.6685872077941895
epoch: 5 step: 15, loss is 4.490316390991211
epoch: 5 step: 16, loss is 4.786681175231934
epoch: 5 step: 17, loss is 4.718393325805664
epoch: 5 step: 18, loss is 4.822529315948486
epoch: 5 step: 19, loss is 4.61546516418457
epoch: 5 step: 20, loss is 4.606862545013428
epoch: 5 step: 21, loss is 4.567031383514404
epoch: 5 step: 22, loss is 4.245269298553467
epoch: 5 step: 23, loss is 4.444795608520508
epoch: 5 step: 24, loss is 4.50244665145874
epoch: 5 step: 25, loss is 4.596442699432373
epoch: 5 step: 26, loss is 4.556334018707275
epoch: 5 step: 27, loss is 4.335491180419922
epoch: 5 step: 28, loss is 4.569363117218018
epoch: 5 step: 29, loss is 4.370438575744629
epoch: 5 step: 30, loss is 4.653420448303223
epoch: 5 step: 31, loss is 4.7220916748046875
epoch: 5 step: 32, loss is 4.386674404144287
epoch: 5 step: 33, loss is 4.468524932861328
epoch: 5 step: 34, loss is 4.364501953125
epoch: 5 step: 35, loss is 4.251172065734863
epoch: 5 step: 36, loss is 4.680960655212402
epoch: 5 step: 37, loss is 4.239577293395996
epoch: 5 step: 38, loss is 4.431349754333496
epoch: 5 step: 39, loss is 4.328549385070801
epoch: 5 step: 40, loss is 4.715191841125488
epoch: 5 step: 41, loss is 4.364654541015625
epoch: 5 step: 42, loss is 4.437411785125732
epoch: 5 step: 43, loss is 4.553417205810547
epoch: 5 step: 44, loss is 4.696696758270264
epoch: 5 step: 45, loss is 4.529208660125732
epoch: 5 step: 46, loss is 4.342605113983154
epoch: 5 step: 47, loss is 4.332080364227295
epoch: 5 step: 48, loss is 4.614562511444092
epoch: 5 step: 49, loss is 4.457653045654297
epoch: 5 step: 50, loss is 4.5105671882629395
epoch: 5 step: 51, loss is 4.598623752593994
epoch: 5 step: 52, loss is 4.53986930847168
epoch: 5 step: 53, loss is 4.6840667724609375
epoch: 5 step: 54, loss is 4.3680596351623535
Train epoch time: 651852.858 ms, per step time: 12071.349 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 12:05:40,203 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.716760158538818
2023-10-13 12:05:52,136 - INFO - valid loss 为: 4.716760158538818
epoch: 6 step: 1, loss is 4.498907566070557
epoch: 6 step: 2, loss is 4.450349807739258
epoch: 6 step: 3, loss is 4.569220066070557
epoch: 6 step: 4, loss is 4.529422283172607
epoch: 6 step: 5, loss is 4.628825664520264
epoch: 6 step: 6, loss is 4.445123195648193
epoch: 6 step: 7, loss is 5.160432815551758
epoch: 6 step: 8, loss is 4.630234718322754
epoch: 6 step: 9, loss is 4.806904315948486
epoch: 6 step: 10, loss is 4.644330024719238
epoch: 6 step: 11, loss is 4.695697784423828
epoch: 6 step: 12, loss is 4.595487117767334
epoch: 6 step: 13, loss is 5.004735469818115
epoch: 6 step: 14, loss is 4.629751205444336
epoch: 6 step: 15, loss is 4.726535320281982
epoch: 6 step: 16, loss is 4.622943878173828
epoch: 6 step: 17, loss is 4.743356704711914
epoch: 6 step: 18, loss is 4.372836589813232
epoch: 6 step: 19, loss is 4.557490825653076
epoch: 6 step: 20, loss is 4.355079174041748
epoch: 6 step: 21, loss is 4.597269058227539
epoch: 6 step: 22, loss is 4.329624652862549
epoch: 6 step: 23, loss is 4.658969402313232
epoch: 6 step: 24, loss is 4.201691150665283
epoch: 6 step: 25, loss is 4.530851364135742
epoch: 6 step: 26, loss is 4.6267313957214355
epoch: 6 step: 27, loss is 4.5510149002075195
epoch: 6 step: 28, loss is 4.607475757598877
epoch: 6 step: 29, loss is 4.281445026397705
epoch: 6 step: 30, loss is 4.52417516708374
epoch: 6 step: 31, loss is 4.646174430847168
epoch: 6 step: 32, loss is 4.643118381500244
epoch: 6 step: 33, loss is 4.185788631439209
epoch: 6 step: 34, loss is 4.83425760269165
epoch: 6 step: 35, loss is 4.88272762298584
epoch: 6 step: 36, loss is 4.595089912414551
epoch: 6 step: 37, loss is 4.70206880569458
epoch: 6 step: 38, loss is 4.5688652992248535
epoch: 6 step: 39, loss is 4.678462505340576
epoch: 6 step: 40, loss is 4.764394760131836
epoch: 6 step: 41, loss is 4.281757831573486
epoch: 6 step: 42, loss is 4.6436896324157715
epoch: 6 step: 43, loss is 4.480116844177246
epoch: 6 step: 44, loss is 4.639019012451172
epoch: 6 step: 45, loss is 4.232821941375732
epoch: 6 step: 46, loss is 4.580719947814941
epoch: 6 step: 47, loss is 4.442659378051758
epoch: 6 step: 48, loss is 4.547231674194336
epoch: 6 step: 49, loss is 4.2392754554748535
epoch: 6 step: 50, loss is 4.411314010620117
epoch: 6 step: 51, loss is 4.540336608886719
epoch: 6 step: 52, loss is 4.582475185394287
epoch: 6 step: 53, loss is 4.295001029968262
epoch: 6 step: 54, loss is 4.487998008728027
Train epoch time: 762425.592 ms, per step time: 14118.992 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 12:18:34,563 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.516962051391602
2023-10-13 12:18:46,850 - INFO - valid loss 为: 4.516962051391602
epoch: 7 step: 1, loss is 4.4852752685546875
epoch: 7 step: 2, loss is 4.515875339508057
epoch: 7 step: 3, loss is 4.286280155181885
epoch: 7 step: 4, loss is 4.319117546081543
epoch: 7 step: 5, loss is 4.444720268249512
epoch: 7 step: 6, loss is 4.365220546722412
epoch: 7 step: 7, loss is 4.563103199005127
epoch: 7 step: 8, loss is 4.310283660888672
epoch: 7 step: 9, loss is 4.458906650543213
epoch: 7 step: 10, loss is 4.495022296905518
epoch: 7 step: 11, loss is 4.339925289154053
epoch: 7 step: 12, loss is 4.656774520874023
epoch: 7 step: 13, loss is 4.7360029220581055
epoch: 7 step: 14, loss is 4.485920429229736
epoch: 7 step: 15, loss is 4.129088401794434
epoch: 7 step: 16, loss is 4.421511650085449
epoch: 7 step: 17, loss is 4.2757439613342285
epoch: 7 step: 18, loss is 4.653073787689209
epoch: 7 step: 19, loss is 4.372497081756592
epoch: 7 step: 20, loss is 4.660862445831299
epoch: 7 step: 21, loss is 4.502007961273193
epoch: 7 step: 22, loss is 4.459734916687012
epoch: 7 step: 23, loss is 4.676013946533203
epoch: 7 step: 24, loss is 4.478224754333496
epoch: 7 step: 25, loss is 4.6176347732543945
epoch: 7 step: 26, loss is 4.705873966217041
epoch: 7 step: 27, loss is 4.495838165283203
epoch: 7 step: 28, loss is 4.327826023101807
epoch: 7 step: 29, loss is 4.696134567260742
epoch: 7 step: 30, loss is 4.642101287841797
epoch: 7 step: 31, loss is 4.611779689788818
epoch: 7 step: 32, loss is 4.376164436340332
epoch: 7 step: 33, loss is 4.505991458892822
epoch: 7 step: 34, loss is 4.485157489776611
epoch: 7 step: 35, loss is 4.596881866455078
epoch: 7 step: 36, loss is 4.683865070343018
epoch: 7 step: 37, loss is 4.569118499755859
epoch: 7 step: 38, loss is 4.292996883392334
epoch: 7 step: 39, loss is 4.48698091506958
epoch: 7 step: 40, loss is 4.573607921600342
epoch: 7 step: 41, loss is 4.460963726043701
epoch: 7 step: 42, loss is 4.6408185958862305
epoch: 7 step: 43, loss is 4.400293827056885
epoch: 7 step: 44, loss is 4.925966739654541
epoch: 7 step: 45, loss is 4.187962532043457
epoch: 7 step: 46, loss is 5.337027072906494
epoch: 7 step: 47, loss is 5.845206260681152
epoch: 7 step: 48, loss is 5.187500953674316
epoch: 7 step: 49, loss is 5.486571311950684
epoch: 7 step: 50, loss is 5.056373596191406
epoch: 7 step: 51, loss is 4.569689750671387
epoch: 7 step: 52, loss is 5.098634243011475
epoch: 7 step: 53, loss is 4.822512149810791
epoch: 7 step: 54, loss is 4.93936014175415
Train epoch time: 836379.986 ms, per step time: 15488.518 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 12:32:43,232 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.872561931610107
2023-10-13 12:32:56,127 - INFO - valid loss 为: 4.872561931610107
epoch: 8 step: 1, loss is 4.964045524597168
epoch: 8 step: 2, loss is 4.508759021759033
epoch: 8 step: 3, loss is 5.094750881195068
epoch: 8 step: 4, loss is 5.651829242706299
epoch: 8 step: 5, loss is 5.074949264526367
epoch: 8 step: 6, loss is 4.778390407562256
epoch: 8 step: 7, loss is 5.606759548187256
epoch: 8 step: 8, loss is 5.444736480712891
epoch: 8 step: 9, loss is 4.584990978240967
epoch: 8 step: 10, loss is 4.6073527336120605
epoch: 8 step: 11, loss is 4.61052942276001
epoch: 8 step: 12, loss is 4.735939025878906
epoch: 8 step: 13, loss is 5.242222785949707
epoch: 8 step: 14, loss is 5.178945541381836
epoch: 8 step: 15, loss is 5.145513534545898
epoch: 8 step: 16, loss is 5.953500270843506
epoch: 8 step: 17, loss is 5.264157295227051
epoch: 8 step: 18, loss is 5.6056437492370605
epoch: 8 step: 19, loss is 4.906492710113525
epoch: 8 step: 20, loss is 5.055714130401611
epoch: 8 step: 21, loss is 5.080442905426025
epoch: 8 step: 22, loss is 5.629791736602783
epoch: 8 step: 23, loss is 5.121914386749268
epoch: 8 step: 24, loss is 5.653415679931641
epoch: 8 step: 25, loss is 5.0858306884765625
epoch: 8 step: 26, loss is 5.074930667877197
epoch: 8 step: 27, loss is 4.9150872230529785
epoch: 8 step: 28, loss is 4.903990268707275
epoch: 8 step: 29, loss is 4.574407577514648
epoch: 8 step: 30, loss is 5.458760738372803
epoch: 8 step: 31, loss is 4.96668815612793
epoch: 8 step: 32, loss is 5.4940104484558105
epoch: 8 step: 33, loss is 5.262426853179932
epoch: 8 step: 34, loss is 5.4091796875
epoch: 8 step: 35, loss is 5.300112724304199
epoch: 8 step: 36, loss is 6.046133041381836
epoch: 8 step: 37, loss is 5.705573558807373
epoch: 8 step: 38, loss is 6.521669387817383
epoch: 8 step: 39, loss is 4.8642730712890625
epoch: 8 step: 40, loss is 6.942435264587402
epoch: 8 step: 41, loss is 6.713602542877197
epoch: 8 step: 42, loss is 7.281832218170166
epoch: 8 step: 43, loss is 5.1840386390686035
epoch: 8 step: 44, loss is 5.726685523986816
epoch: 8 step: 45, loss is 5.94124698638916
epoch: 8 step: 46, loss is 5.392719268798828
epoch: 8 step: 47, loss is 6.823509216308594
epoch: 8 step: 48, loss is 5.772176742553711
epoch: 8 step: 49, loss is 6.695059299468994
epoch: 8 step: 50, loss is 5.758409023284912
epoch: 8 step: 51, loss is 5.484879970550537
epoch: 8 step: 52, loss is 5.724006652832031
epoch: 8 step: 53, loss is 5.246459007263184
epoch: 8 step: 54, loss is 6.728819847106934
Train epoch time: 835049.122 ms, per step time: 15463.873 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 12:46:51,178 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 6.169517993927002
2023-10-13 12:47:02,814 - INFO - valid loss 为: 6.169517993927002
epoch: 9 step: 1, loss is 6.095956802368164
epoch: 9 step: 2, loss is 6.163710117340088
epoch: 9 step: 3, loss is 6.114527225494385
epoch: 9 step: 4, loss is 6.354899883270264
epoch: 9 step: 5, loss is 5.577199935913086
epoch: 9 step: 6, loss is 4.984862804412842
epoch: 9 step: 7, loss is 5.298620700836182
epoch: 9 step: 8, loss is 5.337815761566162
epoch: 9 step: 9, loss is 6.074538230895996
epoch: 9 step: 10, loss is 5.592703342437744
epoch: 9 step: 11, loss is 5.597036838531494
epoch: 9 step: 12, loss is 5.613302707672119
epoch: 9 step: 13, loss is 5.78164005279541
epoch: 9 step: 14, loss is 6.301719665527344
epoch: 9 step: 15, loss is 5.057577610015869
epoch: 9 step: 16, loss is 6.312795639038086
epoch: 9 step: 17, loss is 5.362222671508789
epoch: 9 step: 18, loss is 7.344212055206299
epoch: 9 step: 19, loss is 5.466645240783691
epoch: 9 step: 20, loss is 5.4819159507751465
epoch: 9 step: 21, loss is 6.410478591918945
epoch: 9 step: 22, loss is 5.454595565795898
epoch: 9 step: 23, loss is 6.372060298919678
epoch: 9 step: 24, loss is 5.532260894775391
epoch: 9 step: 25, loss is 5.325908184051514
epoch: 9 step: 26, loss is 5.9338860511779785
epoch: 9 step: 27, loss is 5.964080333709717
epoch: 9 step: 28, loss is 5.342228412628174
epoch: 9 step: 29, loss is 5.104182720184326
epoch: 9 step: 30, loss is 5.988387584686279
epoch: 9 step: 31, loss is 5.614223480224609
epoch: 9 step: 32, loss is 5.7420125007629395
epoch: 9 step: 33, loss is 5.123295783996582
epoch: 9 step: 34, loss is 5.275477886199951
epoch: 9 step: 35, loss is 5.42627477645874
epoch: 9 step: 36, loss is 5.843240737915039
epoch: 9 step: 37, loss is 5.524681568145752
epoch: 9 step: 38, loss is 5.524936199188232
epoch: 9 step: 39, loss is 5.964391231536865
epoch: 9 step: 40, loss is 5.916253089904785
epoch: 9 step: 41, loss is 5.620023727416992
epoch: 9 step: 42, loss is 5.556021213531494
epoch: 9 step: 43, loss is 5.899775505065918
epoch: 9 step: 44, loss is 4.763465404510498
epoch: 9 step: 45, loss is 6.651119232177734
epoch: 9 step: 46, loss is 5.360655784606934
epoch: 9 step: 47, loss is 7.081082344055176
epoch: 9 step: 48, loss is 5.702207088470459
epoch: 9 step: 49, loss is 6.799407958984375
epoch: 9 step: 50, loss is 5.853939533233643
epoch: 9 step: 51, loss is 6.379365921020508
epoch: 9 step: 52, loss is 6.578831672668457
epoch: 9 step: 53, loss is 5.775727272033691
epoch: 9 step: 54, loss is 5.6457624435424805
Train epoch time: 836099.647 ms, per step time: 15483.327 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 13:00:58,915 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.97686243057251
2023-10-13 13:01:11,517 - INFO - valid loss 为: 5.97686243057251
epoch: 10 step: 1, loss is 5.843257427215576
epoch: 10 step: 2, loss is 5.561060428619385
epoch: 10 step: 3, loss is 5.831523895263672
epoch: 10 step: 4, loss is 6.450090408325195
epoch: 10 step: 5, loss is 5.52449893951416
epoch: 10 step: 6, loss is 6.152026176452637
epoch: 10 step: 7, loss is 5.615503787994385
epoch: 10 step: 8, loss is 5.27568244934082
epoch: 10 step: 9, loss is 6.338173866271973
epoch: 10 step: 10, loss is 5.642756462097168
epoch: 10 step: 11, loss is 5.2313947677612305
epoch: 10 step: 12, loss is 5.915040016174316
epoch: 10 step: 13, loss is 6.100041389465332
epoch: 10 step: 14, loss is 5.168295860290527
epoch: 10 step: 15, loss is 5.943027496337891
epoch: 10 step: 16, loss is 5.616915702819824
epoch: 10 step: 17, loss is 5.784509181976318
epoch: 10 step: 18, loss is 5.475574493408203
epoch: 10 step: 19, loss is 6.3416008949279785
epoch: 10 step: 20, loss is 5.551513195037842
epoch: 10 step: 21, loss is 5.279980659484863
epoch: 10 step: 22, loss is 5.408090114593506
epoch: 10 step: 23, loss is 5.630101203918457
epoch: 10 step: 24, loss is 5.653381824493408
epoch: 10 step: 25, loss is 6.3188090324401855
epoch: 10 step: 26, loss is 6.3397135734558105
epoch: 10 step: 27, loss is 5.513979434967041
epoch: 10 step: 28, loss is 6.163888454437256
epoch: 10 step: 29, loss is 6.639961242675781
epoch: 10 step: 30, loss is 5.916245937347412
epoch: 10 step: 31, loss is 5.662573337554932
epoch: 10 step: 32, loss is 5.848239898681641
epoch: 10 step: 33, loss is 6.469501495361328
epoch: 10 step: 34, loss is 6.090443134307861
epoch: 10 step: 35, loss is 5.754745006561279
epoch: 10 step: 36, loss is 5.995843410491943
epoch: 10 step: 37, loss is 5.327340602874756
epoch: 10 step: 38, loss is 5.758034706115723
epoch: 10 step: 39, loss is 5.598047733306885
epoch: 10 step: 40, loss is 6.0807929039001465
epoch: 10 step: 41, loss is 5.608220100402832
epoch: 10 step: 42, loss is 5.67996072769165
epoch: 10 step: 43, loss is 5.766088008880615
epoch: 10 step: 44, loss is 5.661081790924072
epoch: 10 step: 45, loss is 6.014016628265381
epoch: 10 step: 46, loss is 5.360168933868408
epoch: 10 step: 47, loss is 5.404835224151611
epoch: 10 step: 48, loss is 5.565690994262695
epoch: 10 step: 49, loss is 6.26830530166626
epoch: 10 step: 50, loss is 5.457402229309082
epoch: 10 step: 51, loss is 5.65214204788208
epoch: 10 step: 52, loss is 6.172339916229248
epoch: 10 step: 53, loss is 6.151641845703125
epoch: 10 step: 54, loss is 6.463873386383057
Train epoch time: 840282.485 ms, per step time: 15560.787 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 13:15:11,803 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.593414783477783
2023-10-13 13:15:24,673 - INFO - valid loss 为: 5.593414783477783
epoch: 11 step: 1, loss is 6.063910007476807
epoch: 11 step: 2, loss is 6.031067848205566
epoch: 11 step: 3, loss is 6.099432945251465
epoch: 11 step: 4, loss is 5.954709053039551
epoch: 11 step: 5, loss is 6.138883113861084
epoch: 11 step: 6, loss is 5.8248610496521
epoch: 11 step: 7, loss is 5.59846305847168
epoch: 11 step: 8, loss is 5.780947208404541
epoch: 11 step: 9, loss is 6.3042707443237305
epoch: 11 step: 10, loss is 6.2885003089904785
epoch: 11 step: 11, loss is 6.145746231079102
epoch: 11 step: 12, loss is 6.111335277557373
epoch: 11 step: 13, loss is 6.737487316131592
epoch: 11 step: 14, loss is 5.409461498260498
epoch: 11 step: 15, loss is 5.9801788330078125
epoch: 11 step: 16, loss is 6.152159214019775
epoch: 11 step: 17, loss is 5.6900315284729
epoch: 11 step: 18, loss is 5.557733535766602
epoch: 11 step: 19, loss is 6.119352340698242
epoch: 11 step: 20, loss is 5.959420680999756
epoch: 11 step: 21, loss is 5.767953872680664
epoch: 11 step: 22, loss is 5.622542381286621
epoch: 11 step: 23, loss is 6.158494472503662
epoch: 11 step: 24, loss is 5.564412593841553
epoch: 11 step: 25, loss is 5.800795078277588
epoch: 11 step: 26, loss is 5.763645648956299
epoch: 11 step: 27, loss is 5.398136138916016
epoch: 11 step: 28, loss is 6.113789081573486
epoch: 11 step: 29, loss is 5.875046253204346
epoch: 11 step: 30, loss is 5.71837043762207
epoch: 11 step: 31, loss is 6.229432582855225
epoch: 11 step: 32, loss is 5.374774932861328
epoch: 11 step: 33, loss is 5.3344902992248535
epoch: 11 step: 34, loss is 5.352267265319824
epoch: 11 step: 35, loss is 6.62235689163208
epoch: 11 step: 36, loss is 5.619936466217041
epoch: 11 step: 37, loss is 6.036831855773926
epoch: 11 step: 38, loss is 5.21245813369751
epoch: 11 step: 39, loss is 5.37842321395874
epoch: 11 step: 40, loss is 6.17608642578125
epoch: 11 step: 41, loss is 5.433233261108398
epoch: 11 step: 42, loss is 4.957705497741699
epoch: 11 step: 43, loss is 6.05885648727417
epoch: 11 step: 44, loss is 5.25432014465332
epoch: 11 step: 45, loss is 4.9779534339904785
epoch: 11 step: 46, loss is 6.068917274475098
epoch: 11 step: 47, loss is 5.464129447937012
epoch: 11 step: 48, loss is 5.382481098175049
epoch: 11 step: 49, loss is 6.202152252197266
epoch: 11 step: 50, loss is 6.279003143310547
epoch: 11 step: 51, loss is 6.333192348480225
epoch: 11 step: 52, loss is 5.844086170196533
epoch: 11 step: 53, loss is 5.782922267913818
epoch: 11 step: 54, loss is 5.301355838775635
Train epoch time: 786641.385 ms, per step time: 14567.433 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 13:28:31,316 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.2803120613098145
2023-10-13 13:28:44,392 - INFO - valid loss 为: 5.2803120613098145
epoch: 12 step: 1, loss is 5.336516857147217
epoch: 12 step: 2, loss is 5.712705135345459
epoch: 12 step: 3, loss is 5.677825450897217
epoch: 12 step: 4, loss is 5.505125999450684
epoch: 12 step: 5, loss is 6.373480319976807
epoch: 12 step: 6, loss is 5.6366496086120605
epoch: 12 step: 7, loss is 5.254335880279541
epoch: 12 step: 8, loss is 5.856973171234131
epoch: 12 step: 9, loss is 6.230033874511719
epoch: 12 step: 10, loss is 5.634609699249268
epoch: 12 step: 11, loss is 5.821765422821045
epoch: 12 step: 12, loss is 6.324588298797607
epoch: 12 step: 13, loss is 6.049033164978027
epoch: 12 step: 14, loss is 5.850970268249512
epoch: 12 step: 15, loss is 6.36457633972168
epoch: 12 step: 16, loss is 5.513621807098389
epoch: 12 step: 17, loss is 6.4438557624816895
epoch: 12 step: 18, loss is 6.034050941467285
epoch: 12 step: 19, loss is 5.968707084655762
epoch: 12 step: 20, loss is 5.604600429534912
epoch: 12 step: 21, loss is 5.81204080581665
epoch: 12 step: 22, loss is 5.82945442199707
epoch: 12 step: 23, loss is 5.7585978507995605
epoch: 12 step: 24, loss is 5.2762227058410645
epoch: 12 step: 25, loss is 5.308985233306885
epoch: 12 step: 26, loss is 6.081465721130371
epoch: 12 step: 27, loss is 6.038952827453613
epoch: 12 step: 28, loss is 6.004594802856445
epoch: 12 step: 29, loss is 5.674147129058838
epoch: 12 step: 30, loss is 5.473033905029297
epoch: 12 step: 31, loss is 5.490022659301758
epoch: 12 step: 32, loss is 5.518631935119629
epoch: 12 step: 33, loss is 5.589938640594482
epoch: 12 step: 34, loss is 5.564039707183838
epoch: 12 step: 35, loss is 6.105964183807373
epoch: 12 step: 36, loss is 5.966394424438477
epoch: 12 step: 37, loss is 5.702598571777344
epoch: 12 step: 38, loss is 5.671050071716309
epoch: 12 step: 39, loss is 5.649569511413574
epoch: 12 step: 40, loss is 5.7357964515686035
epoch: 12 step: 41, loss is 5.79287052154541
epoch: 12 step: 42, loss is 5.4253129959106445
epoch: 12 step: 43, loss is 5.7492594718933105
epoch: 12 step: 44, loss is 6.0445075035095215
epoch: 12 step: 45, loss is 5.40165376663208
epoch: 12 step: 46, loss is 5.222826957702637
epoch: 12 step: 47, loss is 6.130741596221924
epoch: 12 step: 48, loss is 6.039785861968994
epoch: 12 step: 49, loss is 5.6077165603637695
epoch: 12 step: 50, loss is 5.40334415435791
epoch: 12 step: 51, loss is 5.440059661865234
epoch: 12 step: 52, loss is 5.838022708892822
epoch: 12 step: 53, loss is 5.802072525024414
epoch: 12 step: 54, loss is 5.529957294464111
Train epoch time: 716646.387 ms, per step time: 13271.229 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 13:40:41,040 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.610877513885498
2023-10-13 13:40:54,363 - INFO - valid loss 为: 5.610877513885498
epoch: 13 step: 1, loss is 5.809547424316406
epoch: 13 step: 2, loss is 5.924403190612793
epoch: 13 step: 3, loss is 5.371209621429443
epoch: 13 step: 4, loss is 5.078586578369141
epoch: 13 step: 5, loss is 5.4691362380981445
epoch: 13 step: 6, loss is 5.759430408477783
epoch: 13 step: 7, loss is 5.543277740478516
epoch: 13 step: 8, loss is 5.314297199249268
epoch: 13 step: 9, loss is 5.87131404876709
epoch: 13 step: 10, loss is 5.924489498138428
epoch: 13 step: 11, loss is 5.893834590911865
epoch: 13 step: 12, loss is 5.606287479400635
epoch: 13 step: 13, loss is 5.372130870819092
epoch: 13 step: 14, loss is 5.243719577789307
epoch: 13 step: 15, loss is 5.837558269500732
epoch: 13 step: 16, loss is 5.15507173538208
epoch: 13 step: 17, loss is 5.65579080581665
epoch: 13 step: 18, loss is 6.197588920593262
epoch: 13 step: 19, loss is 5.997640132904053
epoch: 13 step: 20, loss is 5.366301536560059
epoch: 13 step: 21, loss is 5.734002590179443
epoch: 13 step: 22, loss is 5.676981449127197
epoch: 13 step: 23, loss is 5.821044445037842
epoch: 13 step: 24, loss is 5.342663288116455
epoch: 13 step: 25, loss is 6.420345306396484
epoch: 13 step: 26, loss is 5.379914283752441
epoch: 13 step: 27, loss is 5.38950252532959
epoch: 13 step: 28, loss is 5.93120002746582
epoch: 13 step: 29, loss is 5.53642463684082
epoch: 13 step: 30, loss is 5.512421607971191
epoch: 13 step: 31, loss is 5.408319473266602
epoch: 13 step: 32, loss is 5.77300500869751
epoch: 13 step: 33, loss is 5.768791675567627
epoch: 13 step: 34, loss is 5.420781135559082
epoch: 13 step: 35, loss is 5.362613677978516
epoch: 13 step: 36, loss is 5.598361968994141
epoch: 13 step: 37, loss is 5.687378883361816
epoch: 13 step: 38, loss is 5.289012432098389
epoch: 13 step: 39, loss is 5.375686168670654
epoch: 13 step: 40, loss is 5.375608921051025
epoch: 13 step: 41, loss is 5.034383296966553
epoch: 13 step: 42, loss is 5.232994556427002
epoch: 13 step: 43, loss is 4.749488830566406
epoch: 13 step: 44, loss is 5.686629295349121
epoch: 13 step: 45, loss is 5.545245170593262
epoch: 13 step: 46, loss is 5.539074897766113
epoch: 13 step: 47, loss is 5.402395725250244
epoch: 13 step: 48, loss is 5.446552753448486
epoch: 13 step: 49, loss is 5.801279067993164
epoch: 13 step: 50, loss is 5.400321006774902
epoch: 13 step: 51, loss is 5.1981024742126465
epoch: 13 step: 52, loss is 5.510733604431152
epoch: 13 step: 53, loss is 5.170703411102295
epoch: 13 step: 54, loss is 5.458475112915039
Train epoch time: 584615.460 ms, per step time: 10826.212 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 13:50:38,980 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.406540393829346
2023-10-13 13:50:51,642 - INFO - valid loss 为: 5.406540393829346
epoch: 14 step: 1, loss is 5.624848365783691
epoch: 14 step: 2, loss is 5.535193920135498
epoch: 14 step: 3, loss is 5.405511379241943
epoch: 14 step: 4, loss is 6.2828898429870605
epoch: 14 step: 5, loss is 5.545494556427002
epoch: 14 step: 6, loss is 5.2073469161987305
epoch: 14 step: 7, loss is 5.608959197998047
epoch: 14 step: 8, loss is 5.640685081481934
epoch: 14 step: 9, loss is 5.471524715423584
epoch: 14 step: 10, loss is 5.8384809494018555
epoch: 14 step: 11, loss is 5.16480016708374
epoch: 14 step: 12, loss is 5.235016822814941
epoch: 14 step: 13, loss is 5.511648654937744
epoch: 14 step: 14, loss is 5.20005989074707
epoch: 14 step: 15, loss is 5.36398458480835
epoch: 14 step: 16, loss is 5.736933708190918
epoch: 14 step: 17, loss is 5.813764572143555
epoch: 14 step: 18, loss is 5.356668949127197
epoch: 14 step: 19, loss is 5.041548728942871
epoch: 14 step: 20, loss is 5.122737884521484
epoch: 14 step: 21, loss is 5.196857452392578
epoch: 14 step: 22, loss is 5.6726579666137695
epoch: 14 step: 23, loss is 5.3406548500061035
epoch: 14 step: 24, loss is 5.4451518058776855
epoch: 14 step: 25, loss is 5.255856990814209
epoch: 14 step: 26, loss is 5.792637348175049
epoch: 14 step: 27, loss is 5.769085884094238
epoch: 14 step: 28, loss is 5.373936176300049
epoch: 14 step: 29, loss is 5.937399864196777
epoch: 14 step: 30, loss is 5.596931457519531
epoch: 14 step: 31, loss is 6.116949558258057
epoch: 14 step: 32, loss is 6.038637161254883
epoch: 14 step: 33, loss is 5.408360958099365
epoch: 14 step: 34, loss is 5.986242294311523
epoch: 14 step: 35, loss is 5.9514336585998535
epoch: 14 step: 36, loss is 5.565003395080566
epoch: 14 step: 37, loss is 6.2050557136535645
epoch: 14 step: 38, loss is 5.979142189025879
epoch: 14 step: 39, loss is 5.290240287780762
epoch: 14 step: 40, loss is 5.5758137702941895
epoch: 14 step: 41, loss is 5.719773769378662
epoch: 14 step: 42, loss is 5.812251567840576
epoch: 14 step: 43, loss is 5.682672500610352
epoch: 14 step: 44, loss is 5.3703083992004395
epoch: 14 step: 45, loss is 5.933317184448242
epoch: 14 step: 46, loss is 5.714271545410156
epoch: 14 step: 47, loss is 5.397726535797119
epoch: 14 step: 48, loss is 5.168413162231445
epoch: 14 step: 49, loss is 5.277113437652588
epoch: 14 step: 50, loss is 5.7429375648498535
epoch: 14 step: 51, loss is 5.638577938079834
epoch: 14 step: 52, loss is 5.6380839347839355
epoch: 14 step: 53, loss is 5.372369766235352
epoch: 14 step: 54, loss is 5.078876972198486
Train epoch time: 489520.275 ms, per step time: 9065.190 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 13:59:01,166 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.005197048187256
2023-10-13 13:59:13,624 - INFO - valid loss 为: 5.005197048187256
epoch: 15 step: 1, loss is 5.312572479248047
epoch: 15 step: 2, loss is 5.2992143630981445
epoch: 15 step: 3, loss is 5.703591823577881
epoch: 15 step: 4, loss is 5.684962272644043
epoch: 15 step: 5, loss is 5.6202874183654785
epoch: 15 step: 6, loss is 5.5320329666137695
epoch: 15 step: 7, loss is 4.936657428741455
epoch: 15 step: 8, loss is 5.361286163330078
epoch: 15 step: 9, loss is 4.879140377044678
epoch: 15 step: 10, loss is 5.457308769226074
epoch: 15 step: 11, loss is 5.96039342880249
epoch: 15 step: 12, loss is 5.449681758880615
epoch: 15 step: 13, loss is 5.266823768615723
epoch: 15 step: 14, loss is 5.745910167694092
epoch: 15 step: 15, loss is 5.323538780212402
epoch: 15 step: 16, loss is 5.093982696533203
epoch: 15 step: 17, loss is 5.790506362915039
epoch: 15 step: 18, loss is 5.415809631347656
epoch: 15 step: 19, loss is 5.139831066131592
epoch: 15 step: 20, loss is 5.432332992553711
epoch: 15 step: 21, loss is 4.981603622436523
epoch: 15 step: 22, loss is 5.263937950134277
epoch: 15 step: 23, loss is 5.402029991149902
epoch: 15 step: 24, loss is 5.326948165893555
epoch: 15 step: 25, loss is 5.2383599281311035
epoch: 15 step: 26, loss is 5.859694957733154
epoch: 15 step: 27, loss is 5.714568138122559
epoch: 15 step: 28, loss is 5.499211311340332
epoch: 15 step: 29, loss is 5.720384120941162
epoch: 15 step: 30, loss is 5.332581520080566
epoch: 15 step: 31, loss is 5.687857627868652
epoch: 15 step: 32, loss is 5.55333948135376
epoch: 15 step: 33, loss is 5.298593521118164
epoch: 15 step: 34, loss is 5.599336624145508
epoch: 15 step: 35, loss is 5.477110385894775
epoch: 15 step: 36, loss is 5.528985023498535
epoch: 15 step: 37, loss is 5.441864967346191
epoch: 15 step: 38, loss is 5.429485321044922
epoch: 15 step: 39, loss is 5.670837879180908
epoch: 15 step: 40, loss is 5.366580963134766
epoch: 15 step: 41, loss is 5.562865734100342
epoch: 15 step: 42, loss is 5.431081771850586
epoch: 15 step: 43, loss is 5.0695109367370605
epoch: 15 step: 44, loss is 5.583485126495361
epoch: 15 step: 45, loss is 5.555408477783203
epoch: 15 step: 46, loss is 5.066515922546387
epoch: 15 step: 47, loss is 5.80325984954834
epoch: 15 step: 48, loss is 4.956399917602539
epoch: 15 step: 49, loss is 5.388739585876465
epoch: 15 step: 50, loss is 5.468481063842773
epoch: 15 step: 51, loss is 5.631918430328369
epoch: 15 step: 52, loss is 5.169436931610107
epoch: 15 step: 53, loss is 5.619539260864258
epoch: 15 step: 54, loss is 5.558446407318115
Train epoch time: 515323.731 ms, per step time: 9543.032 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 14:07:48,950 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.062646389007568
2023-10-13 14:08:01,921 - INFO - valid loss 为: 5.062646389007568
epoch: 16 step: 1, loss is 5.687758922576904
epoch: 16 step: 2, loss is 5.167531967163086
epoch: 16 step: 3, loss is 5.394577980041504
epoch: 16 step: 4, loss is 5.380655765533447
epoch: 16 step: 5, loss is 5.326732635498047
epoch: 16 step: 6, loss is 5.472823143005371
epoch: 16 step: 7, loss is 5.466124534606934
epoch: 16 step: 8, loss is 5.450763702392578
epoch: 16 step: 9, loss is 5.530813217163086
epoch: 16 step: 10, loss is 5.397485733032227
epoch: 16 step: 11, loss is 5.408310413360596
epoch: 16 step: 12, loss is 5.583687782287598
epoch: 16 step: 13, loss is 4.949395656585693
epoch: 16 step: 14, loss is 5.609278678894043
epoch: 16 step: 15, loss is 5.073568820953369
epoch: 16 step: 16, loss is 5.008790016174316
epoch: 16 step: 17, loss is 4.765775203704834
epoch: 16 step: 18, loss is 5.933311939239502
epoch: 16 step: 19, loss is 5.47369909286499
epoch: 16 step: 20, loss is 5.764870643615723
epoch: 16 step: 21, loss is 5.267129898071289
epoch: 16 step: 22, loss is 5.023995876312256
epoch: 16 step: 23, loss is 5.197370529174805
epoch: 16 step: 24, loss is 5.660181522369385
epoch: 16 step: 25, loss is 5.140294075012207
epoch: 16 step: 26, loss is 4.976115703582764
epoch: 16 step: 27, loss is 5.326340198516846
epoch: 16 step: 28, loss is 5.1235880851745605
epoch: 16 step: 29, loss is 5.630144119262695
epoch: 16 step: 30, loss is 5.22537899017334
epoch: 16 step: 31, loss is 5.029327869415283
epoch: 16 step: 32, loss is 5.217179298400879
epoch: 16 step: 33, loss is 5.203274250030518
epoch: 16 step: 34, loss is 4.948541164398193
epoch: 16 step: 35, loss is 5.07658576965332
epoch: 16 step: 36, loss is 5.160686016082764
epoch: 16 step: 37, loss is 5.244358062744141
epoch: 16 step: 38, loss is 4.869895935058594
epoch: 16 step: 39, loss is 4.781152725219727
epoch: 16 step: 40, loss is 5.751749038696289
epoch: 16 step: 41, loss is 5.559645652770996
epoch: 16 step: 42, loss is 5.488654136657715
epoch: 16 step: 43, loss is 5.103508472442627
epoch: 16 step: 44, loss is 5.60263204574585
epoch: 16 step: 45, loss is 5.2100958824157715
epoch: 16 step: 46, loss is 5.429403781890869
epoch: 16 step: 47, loss is 5.291064262390137
epoch: 16 step: 48, loss is 5.014613151550293
epoch: 16 step: 49, loss is 5.774794578552246
epoch: 16 step: 50, loss is 5.42376708984375
epoch: 16 step: 51, loss is 5.350503444671631
epoch: 16 step: 52, loss is 5.479308605194092
epoch: 16 step: 53, loss is 5.255095958709717
epoch: 16 step: 54, loss is 5.330451965332031
Train epoch time: 485558.537 ms, per step time: 8991.825 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 14:16:07,482 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.949195384979248
2023-10-13 14:16:19,596 - INFO - valid loss 为: 4.949195384979248
epoch: 17 step: 1, loss is 5.258925914764404
epoch: 17 step: 2, loss is 5.274775505065918
epoch: 17 step: 3, loss is 5.371341705322266
epoch: 17 step: 4, loss is 5.310065746307373
epoch: 17 step: 5, loss is 4.993340969085693
epoch: 17 step: 6, loss is 5.102255821228027
epoch: 17 step: 7, loss is 5.0625786781311035
epoch: 17 step: 8, loss is 5.668834686279297
epoch: 17 step: 9, loss is 5.2950639724731445
epoch: 17 step: 10, loss is 5.209890365600586
epoch: 17 step: 11, loss is 5.375278472900391
epoch: 17 step: 12, loss is 5.454730987548828
epoch: 17 step: 13, loss is 5.362895965576172
epoch: 17 step: 14, loss is 5.423350811004639
epoch: 17 step: 15, loss is 4.957319259643555
epoch: 17 step: 16, loss is 5.036920547485352
epoch: 17 step: 17, loss is 5.51997709274292
epoch: 17 step: 18, loss is 5.33319616317749
epoch: 17 step: 19, loss is 5.512837886810303
epoch: 17 step: 20, loss is 5.611636638641357
epoch: 17 step: 21, loss is 6.0160675048828125
epoch: 17 step: 22, loss is 4.867974281311035
epoch: 17 step: 23, loss is 5.826871871948242
epoch: 17 step: 24, loss is 5.2408294677734375
epoch: 17 step: 25, loss is 5.22226619720459
epoch: 17 step: 26, loss is 5.919892311096191
epoch: 17 step: 27, loss is 5.057593822479248
epoch: 17 step: 28, loss is 5.59244441986084
epoch: 17 step: 29, loss is 5.793519973754883
epoch: 17 step: 30, loss is 5.416614532470703
epoch: 17 step: 31, loss is 5.440440654754639
epoch: 17 step: 32, loss is 5.89543342590332
epoch: 17 step: 33, loss is 5.065681457519531
epoch: 17 step: 34, loss is 5.767902374267578
epoch: 17 step: 35, loss is 5.2242751121521
epoch: 17 step: 36, loss is 5.226710319519043
epoch: 17 step: 37, loss is 5.456324577331543
epoch: 17 step: 38, loss is 5.41633939743042
epoch: 17 step: 39, loss is 5.661606788635254
epoch: 17 step: 40, loss is 5.790203094482422
epoch: 17 step: 41, loss is 5.683103084564209
epoch: 17 step: 42, loss is 5.376929759979248
epoch: 17 step: 43, loss is 5.114266395568848
epoch: 17 step: 44, loss is 5.492285251617432
epoch: 17 step: 45, loss is 5.468189239501953
epoch: 17 step: 46, loss is 5.816811561584473
epoch: 17 step: 47, loss is 5.203266143798828
epoch: 17 step: 48, loss is 4.942166328430176
epoch: 17 step: 49, loss is 5.0581769943237305
epoch: 17 step: 50, loss is 5.228854656219482
epoch: 17 step: 51, loss is 4.877407073974609
epoch: 17 step: 52, loss is 5.372463226318359
epoch: 17 step: 53, loss is 5.571770191192627
epoch: 17 step: 54, loss is 4.864070415496826
Train epoch time: 482709.658 ms, per step time: 8939.068 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 14:24:22,307 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.933765411376953
2023-10-13 14:24:35,332 - INFO - valid loss 为: 4.933765411376953
epoch: 18 step: 1, loss is 5.241793155670166
epoch: 18 step: 2, loss is 5.374739170074463
epoch: 18 step: 3, loss is 5.724848747253418
epoch: 18 step: 4, loss is 5.073422908782959
epoch: 18 step: 5, loss is 4.999243259429932
epoch: 18 step: 6, loss is 5.227765083312988
epoch: 18 step: 7, loss is 5.353945255279541
epoch: 18 step: 8, loss is 5.413283348083496
epoch: 18 step: 9, loss is 5.176000118255615
epoch: 18 step: 10, loss is 5.009825229644775
epoch: 18 step: 11, loss is 5.19459867477417
epoch: 18 step: 12, loss is 5.277935028076172
epoch: 18 step: 13, loss is 5.116859436035156
epoch: 18 step: 14, loss is 5.1748552322387695
epoch: 18 step: 15, loss is 5.129454135894775
epoch: 18 step: 16, loss is 5.056591033935547
epoch: 18 step: 17, loss is 5.147218704223633
epoch: 18 step: 18, loss is 4.8705291748046875
epoch: 18 step: 19, loss is 5.235074520111084
epoch: 18 step: 20, loss is 5.220248699188232
epoch: 18 step: 21, loss is 5.076339244842529
epoch: 18 step: 22, loss is 5.264108180999756
epoch: 18 step: 23, loss is 4.959770679473877
epoch: 18 step: 24, loss is 5.415058612823486
epoch: 18 step: 25, loss is 4.754007339477539
epoch: 18 step: 26, loss is 5.257941246032715
epoch: 18 step: 27, loss is 4.7456746101379395
epoch: 18 step: 28, loss is 5.051410675048828
epoch: 18 step: 29, loss is 4.814709186553955
epoch: 18 step: 30, loss is 5.20849084854126
epoch: 18 step: 31, loss is 5.197641372680664
epoch: 18 step: 32, loss is 5.354704856872559
epoch: 18 step: 33, loss is 5.263020038604736
epoch: 18 step: 34, loss is 5.334549903869629
epoch: 18 step: 35, loss is 4.960938930511475
epoch: 18 step: 36, loss is 5.038658142089844
epoch: 18 step: 37, loss is 4.974495887756348
epoch: 18 step: 38, loss is 5.491259574890137
epoch: 18 step: 39, loss is 4.74981689453125
epoch: 18 step: 40, loss is 5.739721298217773
epoch: 18 step: 41, loss is 5.076999187469482
epoch: 18 step: 42, loss is 5.4302873611450195
epoch: 18 step: 43, loss is 5.586090564727783
epoch: 18 step: 44, loss is 5.304525375366211
epoch: 18 step: 45, loss is 5.2206807136535645
epoch: 18 step: 46, loss is 5.194180965423584
epoch: 18 step: 47, loss is 4.99962854385376
epoch: 18 step: 48, loss is 5.1097331047058105
epoch: 18 step: 49, loss is 4.807504177093506
epoch: 18 step: 50, loss is 5.508179187774658
epoch: 18 step: 51, loss is 4.986987113952637
epoch: 18 step: 52, loss is 5.07780122756958
epoch: 18 step: 53, loss is 4.772622108459473
epoch: 18 step: 54, loss is 5.071189880371094
Train epoch time: 486864.553 ms, per step time: 9016.010 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 14:32:42,199 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.798084735870361
2023-10-13 14:32:55,397 - INFO - valid loss 为: 4.798084735870361
epoch: 19 step: 1, loss is 5.065573692321777
epoch: 19 step: 2, loss is 4.897425651550293
epoch: 19 step: 3, loss is 4.993851184844971
epoch: 19 step: 4, loss is 4.886084079742432
epoch: 19 step: 5, loss is 5.135821342468262
epoch: 19 step: 6, loss is 5.179269790649414
epoch: 19 step: 7, loss is 4.998292922973633
epoch: 19 step: 8, loss is 4.821057319641113
epoch: 19 step: 9, loss is 5.088904857635498
epoch: 19 step: 10, loss is 4.941187381744385
epoch: 19 step: 11, loss is 5.171860694885254
epoch: 19 step: 12, loss is 5.223883628845215
epoch: 19 step: 13, loss is 4.855017185211182
epoch: 19 step: 14, loss is 4.8013224601745605
epoch: 19 step: 15, loss is 5.350646018981934
epoch: 19 step: 16, loss is 5.105800628662109
epoch: 19 step: 17, loss is 5.253299236297607
epoch: 19 step: 18, loss is 5.580898284912109
epoch: 19 step: 19, loss is 5.276100158691406
epoch: 19 step: 20, loss is 5.390832901000977
epoch: 19 step: 21, loss is 4.8480119705200195
epoch: 19 step: 22, loss is 5.101260185241699
epoch: 19 step: 23, loss is 5.432043075561523
epoch: 19 step: 24, loss is 5.0314178466796875
epoch: 19 step: 25, loss is 4.998340606689453
epoch: 19 step: 26, loss is 5.646355152130127
epoch: 19 step: 27, loss is 4.906284809112549
epoch: 19 step: 28, loss is 4.935563087463379
epoch: 19 step: 29, loss is 4.697822570800781
epoch: 19 step: 30, loss is 5.638300895690918
epoch: 19 step: 31, loss is 5.599280834197998
epoch: 19 step: 32, loss is 5.54453706741333
epoch: 19 step: 33, loss is 5.459983825683594
epoch: 19 step: 34, loss is 4.98379373550415
epoch: 19 step: 35, loss is 5.245866775512695
epoch: 19 step: 36, loss is 5.116363525390625
epoch: 19 step: 37, loss is 5.219406604766846
epoch: 19 step: 38, loss is 5.380622386932373
epoch: 19 step: 39, loss is 5.434872150421143
epoch: 19 step: 40, loss is 5.4326558113098145
epoch: 19 step: 41, loss is 5.467067718505859
epoch: 19 step: 42, loss is 5.494599342346191
epoch: 19 step: 43, loss is 5.345945358276367
epoch: 19 step: 44, loss is 4.904705047607422
epoch: 19 step: 45, loss is 5.0244460105896
epoch: 19 step: 46, loss is 5.08486795425415
epoch: 19 step: 47, loss is 4.89838171005249
epoch: 19 step: 48, loss is 5.4429030418396
epoch: 19 step: 49, loss is 4.97083044052124
epoch: 19 step: 50, loss is 5.05071496963501
epoch: 19 step: 51, loss is 4.976687431335449
epoch: 19 step: 52, loss is 5.090483665466309
epoch: 19 step: 53, loss is 4.988100528717041
epoch: 19 step: 54, loss is 5.222996711730957
Train epoch time: 482328.184 ms, per step time: 8932.003 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 14:40:57,728 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.769402980804443
2023-10-13 14:41:09,673 - INFO - valid loss 为: 4.769402980804443
epoch: 20 step: 1, loss is 5.107850074768066
epoch: 20 step: 2, loss is 4.680840492248535
epoch: 20 step: 3, loss is 4.9685821533203125
epoch: 20 step: 4, loss is 4.853061199188232
epoch: 20 step: 5, loss is 5.272687911987305
epoch: 20 step: 6, loss is 5.135979175567627
epoch: 20 step: 7, loss is 5.052663803100586
epoch: 20 step: 8, loss is 5.178216457366943
epoch: 20 step: 9, loss is 4.966594696044922
epoch: 20 step: 10, loss is 5.287559986114502
epoch: 20 step: 11, loss is 5.293433666229248
epoch: 20 step: 12, loss is 5.17933464050293
epoch: 20 step: 13, loss is 4.858946800231934
epoch: 20 step: 14, loss is 5.181398868560791
epoch: 20 step: 15, loss is 4.893333435058594
epoch: 20 step: 16, loss is 4.759108066558838
epoch: 20 step: 17, loss is 5.0501708984375
epoch: 20 step: 18, loss is 4.949841499328613
epoch: 20 step: 19, loss is 5.030342102050781
epoch: 20 step: 20, loss is 5.066840171813965
epoch: 20 step: 21, loss is 4.975008487701416
epoch: 20 step: 22, loss is 5.041510581970215
epoch: 20 step: 23, loss is 5.111316680908203
epoch: 20 step: 24, loss is 5.247515678405762
epoch: 20 step: 25, loss is 4.95065975189209
epoch: 20 step: 26, loss is 5.039582252502441
epoch: 20 step: 27, loss is 5.313394546508789
epoch: 20 step: 28, loss is 5.049403190612793
epoch: 20 step: 29, loss is 5.081657409667969
epoch: 20 step: 30, loss is 4.8589348793029785
epoch: 20 step: 31, loss is 5.011491298675537
epoch: 20 step: 32, loss is 5.0930705070495605
epoch: 20 step: 33, loss is 5.326898097991943
epoch: 20 step: 34, loss is 5.189627170562744
epoch: 20 step: 35, loss is 4.878945350646973
epoch: 20 step: 36, loss is 4.861217021942139
epoch: 20 step: 37, loss is 5.1930317878723145
epoch: 20 step: 38, loss is 4.981466293334961
epoch: 20 step: 39, loss is 5.379708290100098
epoch: 20 step: 40, loss is 5.425954341888428
epoch: 20 step: 41, loss is 5.020011901855469
epoch: 20 step: 42, loss is 5.065305709838867
epoch: 20 step: 43, loss is 5.272357940673828
epoch: 20 step: 44, loss is 4.673908710479736
epoch: 20 step: 45, loss is 5.328498363494873
epoch: 20 step: 46, loss is 5.072135925292969
epoch: 20 step: 47, loss is 5.163574695587158
epoch: 20 step: 48, loss is 5.357347011566162
epoch: 20 step: 49, loss is 5.687869548797607
epoch: 20 step: 50, loss is 4.9068427085876465
epoch: 20 step: 51, loss is 5.396966457366943
epoch: 20 step: 52, loss is 5.11022424697876
epoch: 20 step: 53, loss is 5.165716171264648
epoch: 20 step: 54, loss is 5.044835567474365
Train epoch time: 485624.131 ms, per step time: 8993.039 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 14:49:15,299 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.826432704925537
2023-10-13 14:49:27,694 - INFO - valid loss 为: 4.826432704925537
epoch: 21 step: 1, loss is 4.679724216461182
epoch: 21 step: 2, loss is 5.357568264007568
epoch: 21 step: 3, loss is 5.423189163208008
epoch: 21 step: 4, loss is 4.946964740753174
epoch: 21 step: 5, loss is 5.5231781005859375
epoch: 21 step: 6, loss is 5.029095649719238
epoch: 21 step: 7, loss is 5.277216911315918
epoch: 21 step: 8, loss is 5.026719093322754
epoch: 21 step: 9, loss is 5.1525444984436035
epoch: 21 step: 10, loss is 5.061023235321045
epoch: 21 step: 11, loss is 5.560649394989014
epoch: 21 step: 12, loss is 5.414505958557129
epoch: 21 step: 13, loss is 5.411106586456299
epoch: 21 step: 14, loss is 5.259599208831787
epoch: 21 step: 15, loss is 5.010545253753662
epoch: 21 step: 16, loss is 5.486300468444824
epoch: 21 step: 17, loss is 5.01375150680542
epoch: 21 step: 18, loss is 5.220388889312744
epoch: 21 step: 19, loss is 5.3356547355651855
epoch: 21 step: 20, loss is 5.13437557220459
epoch: 21 step: 21, loss is 5.352855682373047
epoch: 21 step: 22, loss is 5.667856216430664
epoch: 21 step: 23, loss is 4.976492881774902
epoch: 21 step: 24, loss is 5.088536262512207
epoch: 21 step: 25, loss is 5.302554607391357
epoch: 21 step: 26, loss is 5.352370262145996
epoch: 21 step: 27, loss is 5.401793003082275
epoch: 21 step: 28, loss is 5.521485328674316
epoch: 21 step: 29, loss is 5.371480941772461
epoch: 21 step: 30, loss is 5.267364501953125
epoch: 21 step: 31, loss is 5.341100692749023
epoch: 21 step: 32, loss is 5.335780143737793
epoch: 21 step: 33, loss is 5.823916435241699
epoch: 21 step: 34, loss is 5.276965141296387
epoch: 21 step: 35, loss is 5.153103828430176
epoch: 21 step: 36, loss is 4.740795135498047
epoch: 21 step: 37, loss is 4.937737464904785
epoch: 21 step: 38, loss is 5.591611862182617
epoch: 21 step: 39, loss is 5.107016086578369
epoch: 21 step: 40, loss is 5.222402095794678
epoch: 21 step: 41, loss is 5.950829982757568
epoch: 21 step: 42, loss is 5.318730354309082
epoch: 21 step: 43, loss is 5.215913772583008
epoch: 21 step: 44, loss is 5.271364688873291
epoch: 21 step: 45, loss is 5.912002086639404
epoch: 21 step: 46, loss is 5.579736709594727
epoch: 21 step: 47, loss is 5.100213527679443
epoch: 21 step: 48, loss is 5.236204147338867
epoch: 21 step: 49, loss is 5.2434515953063965
epoch: 21 step: 50, loss is 5.427346706390381
epoch: 21 step: 51, loss is 5.143576622009277
epoch: 21 step: 52, loss is 5.121736526489258
epoch: 21 step: 53, loss is 5.176940441131592
epoch: 21 step: 54, loss is 4.9604811668396
Train epoch time: 485307.751 ms, per step time: 8987.181 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 14:57:33,004 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 5.002875328063965
2023-10-13 14:57:45,586 - INFO - valid loss 为: 5.002875328063965
epoch: 22 step: 1, loss is 5.035201549530029
epoch: 22 step: 2, loss is 5.173641204833984
epoch: 22 step: 3, loss is 5.074418067932129
epoch: 22 step: 4, loss is 5.0438151359558105
epoch: 22 step: 5, loss is 5.584593296051025
epoch: 22 step: 6, loss is 4.780839443206787
epoch: 22 step: 7, loss is 5.0306806564331055
epoch: 22 step: 8, loss is 5.088313102722168
epoch: 22 step: 9, loss is 4.753727436065674
epoch: 22 step: 10, loss is 5.0227766036987305
epoch: 22 step: 11, loss is 4.892438888549805
epoch: 22 step: 12, loss is 5.3001627922058105
epoch: 22 step: 13, loss is 5.525933742523193
epoch: 22 step: 14, loss is 5.517888069152832
epoch: 22 step: 15, loss is 5.36300802230835
epoch: 22 step: 16, loss is 5.490268707275391
epoch: 22 step: 17, loss is 5.018304347991943
epoch: 22 step: 18, loss is 5.0609660148620605
epoch: 22 step: 19, loss is 5.3830671310424805
epoch: 22 step: 20, loss is 5.70510721206665
epoch: 22 step: 21, loss is 5.913681507110596
epoch: 22 step: 22, loss is 4.919841766357422
epoch: 22 step: 23, loss is 5.857355117797852
epoch: 22 step: 24, loss is 5.194622993469238
epoch: 22 step: 25, loss is 5.098022937774658
epoch: 22 step: 26, loss is 5.000643253326416
epoch: 22 step: 27, loss is 5.327676296234131
epoch: 22 step: 28, loss is 5.051473140716553
epoch: 22 step: 29, loss is 5.2065935134887695
epoch: 22 step: 30, loss is 4.935197830200195
epoch: 22 step: 31, loss is 5.046835422515869
epoch: 22 step: 32, loss is 4.9831109046936035
epoch: 22 step: 33, loss is 4.705868721008301
epoch: 22 step: 34, loss is 5.146362781524658
epoch: 22 step: 35, loss is 5.068739891052246
epoch: 22 step: 36, loss is 4.938136100769043
epoch: 22 step: 37, loss is 5.080118179321289
epoch: 22 step: 38, loss is 5.243943214416504
epoch: 22 step: 39, loss is 4.877229690551758
epoch: 22 step: 40, loss is 5.381443977355957
epoch: 22 step: 41, loss is 4.758521556854248
epoch: 22 step: 42, loss is 5.231058597564697
epoch: 22 step: 43, loss is 5.333742141723633
epoch: 22 step: 44, loss is 5.072518825531006
epoch: 22 step: 45, loss is 5.001629829406738
epoch: 22 step: 46, loss is 5.275893688201904
epoch: 22 step: 47, loss is 4.873272895812988
epoch: 22 step: 48, loss is 4.997701168060303
epoch: 22 step: 49, loss is 4.807608604431152
epoch: 22 step: 50, loss is 5.564782619476318
epoch: 22 step: 51, loss is 5.044050693511963
epoch: 22 step: 52, loss is 5.228707790374756
epoch: 22 step: 53, loss is 4.907659530639648
epoch: 22 step: 54, loss is 4.643156051635742
Train epoch time: 486506.497 ms, per step time: 9009.380 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 15:05:52,094 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.727273941040039
2023-10-13 15:06:05,190 - INFO - valid loss 为: 4.727273941040039
epoch: 23 step: 1, loss is 4.764593124389648
epoch: 23 step: 2, loss is 5.181714057922363
epoch: 23 step: 3, loss is 4.930733680725098
epoch: 23 step: 4, loss is 5.024672031402588
epoch: 23 step: 5, loss is 5.499243259429932
epoch: 23 step: 6, loss is 4.942480087280273
epoch: 23 step: 7, loss is 4.8430962562561035
epoch: 23 step: 8, loss is 5.3645524978637695
epoch: 23 step: 9, loss is 5.095075607299805
epoch: 23 step: 10, loss is 5.208013534545898
epoch: 23 step: 11, loss is 4.702530384063721
epoch: 23 step: 12, loss is 4.89130973815918
epoch: 23 step: 13, loss is 5.088006973266602
epoch: 23 step: 14, loss is 5.4184417724609375
epoch: 23 step: 15, loss is 5.06611967086792
epoch: 23 step: 16, loss is 5.320187091827393
epoch: 23 step: 17, loss is 4.918007850646973
epoch: 23 step: 18, loss is 4.6346259117126465
epoch: 23 step: 19, loss is 5.083475589752197
epoch: 23 step: 20, loss is 4.774141788482666
epoch: 23 step: 21, loss is 5.04407262802124
epoch: 23 step: 22, loss is 5.1621575355529785
epoch: 23 step: 23, loss is 4.781537055969238
epoch: 23 step: 24, loss is 5.120961666107178
epoch: 23 step: 25, loss is 4.875694274902344
epoch: 23 step: 26, loss is 4.561081886291504
epoch: 23 step: 27, loss is 4.821421146392822
epoch: 23 step: 28, loss is 5.346346855163574
epoch: 23 step: 29, loss is 5.001687526702881
epoch: 23 step: 30, loss is 5.127263069152832
epoch: 23 step: 31, loss is 5.361655235290527
epoch: 23 step: 32, loss is 5.352510452270508
epoch: 23 step: 33, loss is 5.360629081726074
epoch: 23 step: 34, loss is 5.257704257965088
epoch: 23 step: 35, loss is 4.962804317474365
epoch: 23 step: 36, loss is 4.973273277282715
epoch: 23 step: 37, loss is 4.76462459564209
epoch: 23 step: 38, loss is 4.875851631164551
epoch: 23 step: 39, loss is 5.328990936279297
epoch: 23 step: 40, loss is 5.240891933441162
epoch: 23 step: 41, loss is 5.275454044342041
epoch: 23 step: 42, loss is 5.184125900268555
epoch: 23 step: 43, loss is 5.1587300300598145
epoch: 23 step: 44, loss is 5.0877766609191895
epoch: 23 step: 45, loss is 5.025866508483887
epoch: 23 step: 46, loss is 4.925375938415527
epoch: 23 step: 47, loss is 5.130640506744385
epoch: 23 step: 48, loss is 5.19352388381958
epoch: 23 step: 49, loss is 5.176614284515381
epoch: 23 step: 50, loss is 5.529431343078613
epoch: 23 step: 51, loss is 5.4919819831848145
epoch: 23 step: 52, loss is 4.9616475105285645
epoch: 23 step: 53, loss is 5.0606513023376465
epoch: 23 step: 54, loss is 5.03588342666626
Train epoch time: 485021.585 ms, per step time: 8981.881 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 15:14:10,214 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.771082401275635
2023-10-13 15:14:22,598 - INFO - valid loss 为: 4.771082401275635
epoch: 24 step: 1, loss is 5.0900092124938965
epoch: 24 step: 2, loss is 5.306375980377197
epoch: 24 step: 3, loss is 5.387109279632568
epoch: 24 step: 4, loss is 5.319073677062988
epoch: 24 step: 5, loss is 5.657306671142578
epoch: 24 step: 6, loss is 5.1771159172058105
epoch: 24 step: 7, loss is 4.626291275024414
epoch: 24 step: 8, loss is 5.064983367919922
epoch: 24 step: 9, loss is 4.818223476409912
epoch: 24 step: 10, loss is 5.0290207862854
epoch: 24 step: 11, loss is 5.097384929656982
epoch: 24 step: 12, loss is 5.310386657714844
epoch: 24 step: 13, loss is 4.71625280380249
epoch: 24 step: 14, loss is 4.83342981338501
epoch: 24 step: 15, loss is 5.119662284851074
epoch: 24 step: 16, loss is 4.975935459136963
epoch: 24 step: 17, loss is 5.204164028167725
epoch: 24 step: 18, loss is 4.8765339851379395
epoch: 24 step: 19, loss is 5.154991149902344
epoch: 24 step: 20, loss is 5.139927864074707
epoch: 24 step: 21, loss is 4.920511245727539
epoch: 24 step: 22, loss is 5.087169170379639
epoch: 24 step: 23, loss is 4.96281623840332
epoch: 24 step: 24, loss is 5.099741458892822
epoch: 24 step: 25, loss is 5.28258752822876
epoch: 24 step: 26, loss is 4.719365119934082
epoch: 24 step: 27, loss is 4.9707231521606445
epoch: 24 step: 28, loss is 4.967795372009277
epoch: 24 step: 29, loss is 5.492573261260986
epoch: 24 step: 30, loss is 5.175132751464844
epoch: 24 step: 31, loss is 5.16425895690918
epoch: 24 step: 32, loss is 5.20261287689209
epoch: 24 step: 33, loss is 5.184849739074707
epoch: 24 step: 34, loss is 5.603292465209961
epoch: 24 step: 35, loss is 5.409094333648682
epoch: 24 step: 36, loss is 5.20188045501709
epoch: 24 step: 37, loss is 4.966403961181641
epoch: 24 step: 38, loss is 5.3850908279418945
epoch: 24 step: 39, loss is 4.851944446563721
epoch: 24 step: 40, loss is 5.1120452880859375
epoch: 24 step: 41, loss is 5.2614898681640625
epoch: 24 step: 42, loss is 5.070934772491455
epoch: 24 step: 43, loss is 5.37177848815918
epoch: 24 step: 44, loss is 5.383039474487305
epoch: 24 step: 45, loss is 4.888242244720459
epoch: 24 step: 46, loss is 5.010944843292236
epoch: 24 step: 47, loss is 4.828129768371582
epoch: 24 step: 48, loss is 5.182486057281494
epoch: 24 step: 49, loss is 5.067731857299805
epoch: 24 step: 50, loss is 5.143890380859375
epoch: 24 step: 51, loss is 4.8803019523620605
epoch: 24 step: 52, loss is 5.281724452972412
epoch: 24 step: 53, loss is 4.895946025848389
epoch: 24 step: 54, loss is 5.235072135925293
Train epoch time: 485906.301 ms, per step time: 8998.265 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 15:22:28,506 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.760834217071533
2023-10-13 15:22:41,815 - INFO - valid loss 为: 4.760834217071533
epoch: 25 step: 1, loss is 5.348095893859863
epoch: 25 step: 2, loss is 4.88894510269165
epoch: 25 step: 3, loss is 5.078507900238037
epoch: 25 step: 4, loss is 5.286448955535889
epoch: 25 step: 5, loss is 5.107089996337891
epoch: 25 step: 6, loss is 5.063148021697998
epoch: 25 step: 7, loss is 4.996705532073975
epoch: 25 step: 8, loss is 5.06343412399292
epoch: 25 step: 9, loss is 5.135464191436768
epoch: 25 step: 10, loss is 4.6244425773620605
epoch: 25 step: 11, loss is 5.561479568481445
epoch: 25 step: 12, loss is 4.726405620574951
epoch: 25 step: 13, loss is 4.882628917694092
epoch: 25 step: 14, loss is 4.943704605102539
epoch: 25 step: 15, loss is 5.211844444274902
epoch: 25 step: 16, loss is 4.702615737915039
epoch: 25 step: 17, loss is 5.125177383422852
epoch: 25 step: 18, loss is 5.233635902404785
epoch: 25 step: 19, loss is 4.858457565307617
epoch: 25 step: 20, loss is 5.1017279624938965
epoch: 25 step: 21, loss is 4.533571243286133
epoch: 25 step: 22, loss is 5.039062023162842
epoch: 25 step: 23, loss is 5.032890796661377
epoch: 25 step: 24, loss is 4.898227691650391
epoch: 25 step: 25, loss is 4.885498523712158
epoch: 25 step: 26, loss is 5.195633411407471
epoch: 25 step: 27, loss is 5.097869396209717
epoch: 25 step: 28, loss is 4.971386909484863
epoch: 25 step: 29, loss is 4.885909080505371
epoch: 25 step: 30, loss is 4.619811534881592
epoch: 25 step: 31, loss is 4.8587846755981445
epoch: 25 step: 32, loss is 5.062914848327637
epoch: 25 step: 33, loss is 4.77410888671875
epoch: 25 step: 34, loss is 4.748701095581055
epoch: 25 step: 35, loss is 4.842865943908691
epoch: 25 step: 36, loss is 5.005938529968262
epoch: 25 step: 37, loss is 4.952552318572998
epoch: 25 step: 38, loss is 4.932798862457275
epoch: 25 step: 39, loss is 4.965381622314453
epoch: 25 step: 40, loss is 5.259739398956299
epoch: 25 step: 41, loss is 4.854515075683594
epoch: 25 step: 42, loss is 4.997285842895508
epoch: 25 step: 43, loss is 4.894482135772705
epoch: 25 step: 44, loss is 4.856784343719482
epoch: 25 step: 45, loss is 5.051261901855469
epoch: 25 step: 46, loss is 5.0354790687561035
epoch: 25 step: 47, loss is 5.289947509765625
epoch: 25 step: 48, loss is 5.619428634643555
epoch: 25 step: 49, loss is 4.778927326202393
epoch: 25 step: 50, loss is 5.072376728057861
epoch: 25 step: 51, loss is 4.962541103363037
epoch: 25 step: 52, loss is 5.11842155456543
epoch: 25 step: 53, loss is 4.75252628326416
epoch: 25 step: 54, loss is 4.880995273590088
Train epoch time: 481747.952 ms, per step time: 8921.258 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 15:30:43,565 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.761825084686279
2023-10-13 15:30:56,616 - INFO - valid loss 为: 4.761825084686279
epoch: 26 step: 1, loss is 4.879567623138428
epoch: 26 step: 2, loss is 5.1289753913879395
epoch: 26 step: 3, loss is 5.2363057136535645
epoch: 26 step: 4, loss is 5.107409477233887
epoch: 26 step: 5, loss is 4.518704891204834
epoch: 26 step: 6, loss is 4.741903781890869
epoch: 26 step: 7, loss is 4.875297546386719
epoch: 26 step: 8, loss is 4.696983814239502
epoch: 26 step: 9, loss is 4.719364166259766
epoch: 26 step: 10, loss is 4.782543659210205
epoch: 26 step: 11, loss is 4.876784324645996
epoch: 26 step: 12, loss is 4.8854756355285645
epoch: 26 step: 13, loss is 4.813131332397461
epoch: 26 step: 14, loss is 4.8631272315979
epoch: 26 step: 15, loss is 4.995951175689697
epoch: 26 step: 16, loss is 4.77330207824707
epoch: 26 step: 17, loss is 4.808253765106201
epoch: 26 step: 18, loss is 5.344392776489258
epoch: 26 step: 19, loss is 4.878035545349121
epoch: 26 step: 20, loss is 5.10228157043457
epoch: 26 step: 21, loss is 4.728597640991211
epoch: 26 step: 22, loss is 5.0244832038879395
epoch: 26 step: 23, loss is 5.077001094818115
epoch: 26 step: 24, loss is 4.7213134765625
epoch: 26 step: 25, loss is 4.741288661956787
epoch: 26 step: 26, loss is 4.93673038482666
epoch: 26 step: 27, loss is 4.707118511199951
epoch: 26 step: 28, loss is 4.585309982299805
epoch: 26 step: 29, loss is 4.754621982574463
epoch: 26 step: 30, loss is 4.847450256347656
epoch: 26 step: 31, loss is 4.6541972160339355
epoch: 26 step: 32, loss is 4.896744251251221
epoch: 26 step: 33, loss is 5.0718159675598145
epoch: 26 step: 34, loss is 4.732542037963867
epoch: 26 step: 35, loss is 4.730957984924316
epoch: 26 step: 36, loss is 4.684963703155518
epoch: 26 step: 37, loss is 5.023280143737793
epoch: 26 step: 38, loss is 4.636829376220703
epoch: 26 step: 39, loss is 5.381032466888428
epoch: 26 step: 40, loss is 4.8848700523376465
epoch: 26 step: 41, loss is 4.980409622192383
epoch: 26 step: 42, loss is 5.05344820022583
epoch: 26 step: 43, loss is 4.885494232177734
epoch: 26 step: 44, loss is 4.819431781768799
epoch: 26 step: 45, loss is 5.020755767822266
epoch: 26 step: 46, loss is 4.630803108215332
epoch: 26 step: 47, loss is 5.068104267120361
epoch: 26 step: 48, loss is 5.354531288146973
epoch: 26 step: 49, loss is 5.012265682220459
epoch: 26 step: 50, loss is 4.832334995269775
epoch: 26 step: 51, loss is 4.969603538513184
epoch: 26 step: 52, loss is 4.666258811950684
epoch: 26 step: 53, loss is 4.965868949890137
epoch: 26 step: 54, loss is 4.910716533660889
Train epoch time: 486486.219 ms, per step time: 9009.004 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 15:39:03,104 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.570878982543945
2023-10-13 15:39:14,894 - INFO - valid loss 为: 4.570878982543945
epoch: 27 step: 1, loss is 4.948574542999268
epoch: 27 step: 2, loss is 4.558469772338867
epoch: 27 step: 3, loss is 5.110993385314941
epoch: 27 step: 4, loss is 4.802982330322266
epoch: 27 step: 5, loss is 4.827188491821289
epoch: 27 step: 6, loss is 5.550387859344482
epoch: 27 step: 7, loss is 5.233905792236328
epoch: 27 step: 8, loss is 5.427300930023193
epoch: 27 step: 9, loss is 4.797877788543701
epoch: 27 step: 10, loss is 5.331621170043945
epoch: 27 step: 11, loss is 5.089129447937012
epoch: 27 step: 12, loss is 5.140790939331055
epoch: 27 step: 13, loss is 4.736934185028076
epoch: 27 step: 14, loss is 5.064902305603027
epoch: 27 step: 15, loss is 4.735384941101074
epoch: 27 step: 16, loss is 5.013619899749756
epoch: 27 step: 17, loss is 5.086971759796143
epoch: 27 step: 18, loss is 4.680081367492676
epoch: 27 step: 19, loss is 4.94476318359375
epoch: 27 step: 20, loss is 5.334203243255615
epoch: 27 step: 21, loss is 5.135823726654053
epoch: 27 step: 22, loss is 5.054969310760498
epoch: 27 step: 23, loss is 5.084682941436768
epoch: 27 step: 24, loss is 4.718458652496338
epoch: 27 step: 25, loss is 5.050412654876709
epoch: 27 step: 26, loss is 4.6890034675598145
epoch: 27 step: 27, loss is 4.962461471557617
epoch: 27 step: 28, loss is 5.001649379730225
epoch: 27 step: 29, loss is 5.315399169921875
epoch: 27 step: 30, loss is 5.412038803100586
epoch: 27 step: 31, loss is 4.606710910797119
epoch: 27 step: 32, loss is 4.794372081756592
epoch: 27 step: 33, loss is 4.415987968444824
epoch: 27 step: 34, loss is 5.322638034820557
epoch: 27 step: 35, loss is 5.039635181427002
epoch: 27 step: 36, loss is 4.81392765045166
epoch: 27 step: 37, loss is 5.007370948791504
epoch: 27 step: 38, loss is 4.947033405303955
epoch: 27 step: 39, loss is 4.977837562561035
epoch: 27 step: 40, loss is 5.218875408172607
epoch: 27 step: 41, loss is 5.003376007080078
epoch: 27 step: 42, loss is 5.307293891906738
epoch: 27 step: 43, loss is 4.739864826202393
epoch: 27 step: 44, loss is 5.198207855224609
epoch: 27 step: 45, loss is 4.89293098449707
epoch: 27 step: 46, loss is 4.582409381866455
epoch: 27 step: 47, loss is 4.656246185302734
epoch: 27 step: 48, loss is 5.00689172744751
epoch: 27 step: 49, loss is 4.768712997436523
epoch: 27 step: 50, loss is 4.888279914855957
epoch: 27 step: 51, loss is 4.890130996704102
epoch: 27 step: 52, loss is 4.7417988777160645
epoch: 27 step: 53, loss is 4.841911315917969
epoch: 27 step: 54, loss is 4.824647903442383
Train epoch time: 481813.626 ms, per step time: 8922.475 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 15:47:16,710 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.551751613616943
2023-10-13 15:47:29,844 - INFO - valid loss 为: 4.551751613616943
epoch: 28 step: 1, loss is 5.022826194763184
epoch: 28 step: 2, loss is 4.90134859085083
epoch: 28 step: 3, loss is 5.047844409942627
epoch: 28 step: 4, loss is 4.5032429695129395
epoch: 28 step: 5, loss is 4.8867106437683105
epoch: 28 step: 6, loss is 4.7995991706848145
epoch: 28 step: 7, loss is 4.833082675933838
epoch: 28 step: 8, loss is 5.023965358734131
epoch: 28 step: 9, loss is 5.488991737365723
epoch: 28 step: 10, loss is 4.800772666931152
epoch: 28 step: 11, loss is 4.94949197769165
epoch: 28 step: 12, loss is 4.899999618530273
epoch: 28 step: 13, loss is 5.088395118713379
epoch: 28 step: 14, loss is 4.953957557678223
epoch: 28 step: 15, loss is 4.729996204376221
epoch: 28 step: 16, loss is 4.7197346687316895
epoch: 28 step: 17, loss is 5.024730205535889
epoch: 28 step: 18, loss is 4.966280937194824
epoch: 28 step: 19, loss is 4.8804402351379395
epoch: 28 step: 20, loss is 4.501866817474365
epoch: 28 step: 21, loss is 4.832374095916748
epoch: 28 step: 22, loss is 4.945874214172363
epoch: 28 step: 23, loss is 5.0927534103393555
epoch: 28 step: 24, loss is 4.9196672439575195
epoch: 28 step: 25, loss is 4.948973178863525
epoch: 28 step: 26, loss is 4.8755011558532715
epoch: 28 step: 27, loss is 4.556307315826416
epoch: 28 step: 28, loss is 4.518235206604004
epoch: 28 step: 29, loss is 5.401702880859375
epoch: 28 step: 30, loss is 4.964405059814453
epoch: 28 step: 31, loss is 4.748806476593018
epoch: 28 step: 32, loss is 4.956839561462402
epoch: 28 step: 33, loss is 4.801625728607178
epoch: 28 step: 34, loss is 4.724061012268066
epoch: 28 step: 35, loss is 4.9988532066345215
epoch: 28 step: 36, loss is 5.15317440032959
epoch: 28 step: 37, loss is 4.900237083435059
epoch: 28 step: 38, loss is 5.002295970916748
epoch: 28 step: 39, loss is 4.794308185577393
epoch: 28 step: 40, loss is 5.210616111755371
epoch: 28 step: 41, loss is 4.985568523406982
epoch: 28 step: 42, loss is 5.0705389976501465
epoch: 28 step: 43, loss is 4.780904769897461
epoch: 28 step: 44, loss is 4.936966419219971
epoch: 28 step: 45, loss is 4.960032939910889
epoch: 28 step: 46, loss is 4.575089454650879
epoch: 28 step: 47, loss is 5.200344562530518
epoch: 28 step: 48, loss is 5.005289554595947
epoch: 28 step: 49, loss is 4.908720970153809
epoch: 28 step: 50, loss is 4.826625347137451
epoch: 28 step: 51, loss is 5.038491249084473
epoch: 28 step: 52, loss is 4.769443988800049
epoch: 28 step: 53, loss is 4.75458288192749
epoch: 28 step: 54, loss is 4.524509429931641
Train epoch time: 483485.995 ms, per step time: 8953.444 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 15:55:33,332 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.888452529907227
2023-10-13 15:55:45,821 - INFO - valid loss 为: 4.888452529907227
epoch: 29 step: 1, loss is 4.856627464294434
epoch: 29 step: 2, loss is 4.70538854598999
epoch: 29 step: 3, loss is 5.073504447937012
epoch: 29 step: 4, loss is 4.682156085968018
epoch: 29 step: 5, loss is 4.8714141845703125
epoch: 29 step: 6, loss is 5.0421857833862305
epoch: 29 step: 7, loss is 4.536205768585205
epoch: 29 step: 8, loss is 5.23207950592041
epoch: 29 step: 9, loss is 5.077890872955322
epoch: 29 step: 10, loss is 4.688292503356934
epoch: 29 step: 11, loss is 4.562349319458008
epoch: 29 step: 12, loss is 4.804724216461182
epoch: 29 step: 13, loss is 4.613630294799805
epoch: 29 step: 14, loss is 4.775509834289551
epoch: 29 step: 15, loss is 4.387660026550293
epoch: 29 step: 16, loss is 4.900309085845947
epoch: 29 step: 17, loss is 4.724424362182617
epoch: 29 step: 18, loss is 4.760458469390869
epoch: 29 step: 19, loss is 5.094753265380859
epoch: 29 step: 20, loss is 5.031643390655518
epoch: 29 step: 21, loss is 5.063231945037842
epoch: 29 step: 22, loss is 4.780394554138184
epoch: 29 step: 23, loss is 4.368993759155273
epoch: 29 step: 24, loss is 4.873100757598877
epoch: 29 step: 25, loss is 4.855087757110596
epoch: 29 step: 26, loss is 4.492761135101318
epoch: 29 step: 27, loss is 5.338951587677002
epoch: 29 step: 28, loss is 4.605425834655762
epoch: 29 step: 29, loss is 4.611502647399902
epoch: 29 step: 30, loss is 4.607366561889648
epoch: 29 step: 31, loss is 4.494826316833496
epoch: 29 step: 32, loss is 4.703007698059082
epoch: 29 step: 33, loss is 4.707972049713135
epoch: 29 step: 34, loss is 4.777863025665283
epoch: 29 step: 35, loss is 5.309651851654053
epoch: 29 step: 36, loss is 4.907323837280273
epoch: 29 step: 37, loss is 4.862210750579834
epoch: 29 step: 38, loss is 5.122491836547852
epoch: 29 step: 39, loss is 5.5050578117370605
epoch: 29 step: 40, loss is 4.517633438110352
epoch: 29 step: 41, loss is 4.677402496337891
epoch: 29 step: 42, loss is 4.807634353637695
epoch: 29 step: 43, loss is 4.950710296630859
epoch: 29 step: 44, loss is 5.1617512702941895
epoch: 29 step: 45, loss is 5.123488903045654
epoch: 29 step: 46, loss is 4.855820655822754
epoch: 29 step: 47, loss is 5.593893051147461
epoch: 29 step: 48, loss is 4.955189228057861
epoch: 29 step: 49, loss is 5.178853511810303
epoch: 29 step: 50, loss is 5.292712211608887
epoch: 29 step: 51, loss is 5.22749662399292
epoch: 29 step: 52, loss is 4.839639663696289
epoch: 29 step: 53, loss is 4.996126174926758
epoch: 29 step: 54, loss is 5.053580284118652
Train epoch time: 483994.053 ms, per step time: 8962.853 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 16:03:49,817 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.79551362991333
2023-10-13 16:04:02,105 - INFO - valid loss 为: 4.79551362991333
epoch: 30 step: 1, loss is 5.1306962966918945
epoch: 30 step: 2, loss is 4.654359340667725
epoch: 30 step: 3, loss is 4.667093753814697
epoch: 30 step: 4, loss is 4.875414848327637
epoch: 30 step: 5, loss is 4.5882978439331055
epoch: 30 step: 6, loss is 5.007932186126709
epoch: 30 step: 7, loss is 5.521369457244873
epoch: 30 step: 8, loss is 5.090661525726318
epoch: 30 step: 9, loss is 4.941851615905762
epoch: 30 step: 10, loss is 4.689058303833008
epoch: 30 step: 11, loss is 4.800131320953369
epoch: 30 step: 12, loss is 4.678913116455078
epoch: 30 step: 13, loss is 5.205959320068359
epoch: 30 step: 14, loss is 4.798870086669922
epoch: 30 step: 15, loss is 4.852346897125244
epoch: 30 step: 16, loss is 4.997870922088623
epoch: 30 step: 17, loss is 4.5198163986206055
epoch: 30 step: 18, loss is 5.092394828796387
epoch: 30 step: 19, loss is 5.198429584503174
epoch: 30 step: 20, loss is 4.921724319458008
epoch: 30 step: 21, loss is 4.7839484214782715
epoch: 30 step: 22, loss is 4.802585124969482
epoch: 30 step: 23, loss is 4.898660659790039
epoch: 30 step: 24, loss is 5.109120845794678
epoch: 30 step: 25, loss is 4.7026262283325195
epoch: 30 step: 26, loss is 5.114261150360107
epoch: 30 step: 27, loss is 4.7162933349609375
epoch: 30 step: 28, loss is 4.388290882110596
epoch: 30 step: 29, loss is 4.8003997802734375
epoch: 30 step: 30, loss is 4.807464122772217
epoch: 30 step: 31, loss is 4.387157440185547
epoch: 30 step: 32, loss is 5.131628513336182
epoch: 30 step: 33, loss is 4.765379905700684
epoch: 30 step: 34, loss is 4.952288627624512
epoch: 30 step: 35, loss is 4.7694478034973145
epoch: 30 step: 36, loss is 4.890872001647949
epoch: 30 step: 37, loss is 5.0091352462768555
epoch: 30 step: 38, loss is 5.014907360076904
epoch: 30 step: 39, loss is 5.295699119567871
epoch: 30 step: 40, loss is 4.7698798179626465
epoch: 30 step: 41, loss is 4.432782173156738
epoch: 30 step: 42, loss is 4.7520246505737305
epoch: 30 step: 43, loss is 4.838479518890381
epoch: 30 step: 44, loss is 5.044980525970459
epoch: 30 step: 45, loss is 5.014964580535889
epoch: 30 step: 46, loss is 4.843555450439453
epoch: 30 step: 47, loss is 4.487791061401367
epoch: 30 step: 48, loss is 4.997437477111816
epoch: 30 step: 49, loss is 4.848555088043213
epoch: 30 step: 50, loss is 4.9368743896484375
epoch: 30 step: 51, loss is 5.054574012756348
epoch: 30 step: 52, loss is 4.7146687507629395
epoch: 30 step: 53, loss is 4.882843971252441
epoch: 30 step: 54, loss is 4.695909023284912
Train epoch time: 482758.394 ms, per step time: 8939.970 ms
INFO:root:current lr 为：0.009999999776482582
2023-10-13 16:12:04,866 - INFO - current lr 为：0.009999999776482582
INFO:root:valid loss 为: 4.544013500213623
2023-10-13 16:12:17,609 - INFO - valid loss 为: 4.544013500213623
INFO:root:Loaded model at /cache/code/m-libcity/M_libcity/cache/7064/model_cache/DCRNN_NYCBike20140409.ckpt
2023-10-13 16:12:17,615 - INFO - Loaded model at /cache/code/m-libcity/M_libcity/cache/7064/model_cache/DCRNN_NYCBike20140409.ckpt
INFO:root:Start evaluating ...
2023-10-13 16:12:17,733 - INFO - Start evaluating ...
INFO:root:Note that you select the single mode to evaluate!
(384, 12, 2)
2023-10-13 16:16:40,564 - INFO - Note that you select the single mode to evaluate!
INFO:root:Evaluate result is saved at /cache/code/m-libcity/M_libcity/cache/7064/evaluate_cache/2023_10_13_16_16_45_DCRNN_NYCBike20140409.csv
2023-10-13 16:16:46,103 - INFO - Evaluate result is saved at /cache/code/m-libcity/M_libcity/cache/7064/evaluate_cache/2023_10_13_16_16_45_DCRNN_NYCBike20140409.csv
INFO:root:
         MAE        MAPE        MSE       RMSE masked_MAE masked_MAPE masked_MSE masked_RMSE
1  3.2272842  0.26913357  36.102764  6.0085573  4.8511944  0.51104695   65.34741    8.083774
INFO:root:List OBS time cost: 0.00 seconds.
*********************
/cache/code/m-libcity/M_libcity/cache/
2023-10-13 16:16:46,176 - INFO - List OBS time cost: 0.00 seconds.
INFO:root:Copy parallel total time cost: 1.32 seconds.
2023-10-13 16:16:47,490 - INFO - Copy parallel total time cost: 1.32 seconds.
Successfully Upload /cache/code/m-libcity/M_libcity/cache/ to /cache/output

[INFO] ME(366:281473255406144,MainProcess):2023-10-13-16:16:56.107.607 [mindspore/_extends/remote/kernel_build_server_ascend.py:65] [TRACE] Ascend Messager Exit...
[INFO] PIPELINE(366,ffff9966fa40,python):2023-10-13-16:16:56.110.449 [mindspore/ccsrc/pipeline/jit/init.cc:412] operator()] Start releasing dataset handles...
[INFO] PIPELINE(366,ffff9966fa40,python):2023-10-13-16:16:56.110.552 [mindspore/ccsrc/pipeline/jit/init.cc:415] operator()] End release dataset handles.
[INFO] PIPELINE(366,ffff9966fa40,python):2023-10-13-16:16:56.110.571 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1884] FinalizeCluster] Start finalize the cluster instance.
[INFO] PIPELINE(366,ffff9966fa40,python):2023-10-13-16:16:56.110.595 [mindspore/ccsrc/pipeline/jit/pipeline.cc:1891] FinalizeCluster] End finalize the cluster instance.
time="2023-10-13T16:16:58+08:00" level=info msg="clean up child process succeed, pid=366, wstatus=0, exit_status=0" file="cleaner_unix.go:75" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T16:16:58+08:00" level=info msg="clean up child process succeed, pid=472, wstatus=0, exit_status=0" file="cleaner_unix.go:75" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T16:16:58+08:00" level=info msg="clean up child process succeed, pid=473, wstatus=0, exit_status=0" file="cleaner_unix.go:75" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
INFO:root:List OBS time cost: 8.18 seconds.
download code successfully
unzip code successfully
INFO:root:Copy parallel total time cost: 16.31 seconds.
upload model successfully
download system code successfully
[ModelArts Service Log]2023-10-13 16:17:11,795 - INFO - Begin destroy training processes
[ModelArts Service Log]2023-10-13 16:17:11,796 - INFO - proc-rank-0-device-0 (pid: 129) has exited
[ModelArts Service Log]2023-10-13 16:17:11,796 - INFO - End destroy training processes
time="2023-10-13T16:17:11+08:00" level=info msg="clean up child process succeed, pid=130, wstatus=0, exit_status=0" file="cleaner_unix.go:75" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T16:17:11+08:00" level=warning msg="waiting for cmd process, but got ECHILD error" file="run_train.go:367" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T16:17:16+08:00" level=warning msg="report event TrainingExit failed: send training-event info to algorancher failed, err: Post \"https://modelarts.cn-east-321.nbaicc.com/v2/17c194e82d5f4ec68a451515b77a1b5b/training-jobs/2c4fde60-364b-472d-a00f-922d0618e076/tasks/worker-0/reports/training-event\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)" file="event.go:51" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T16:17:16+08:00" level=info msg="bootstrap is exiting with exit code 0" file="bootstrap.go:241" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T16:17:16+08:00" level=info msg="retCode 0 has been written to the retCode file /home/ma-user/modelarts/retCode" file="bootstrap.go:221" Command=bootstrap/run Component=ma-training-toolkit Platform=ModelArts-Service
time="2023-10-13T16:17:17+08:00" level=info msg="[sidecar] training is completed" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T16:17:17+08:00" level=info msg="[sidecar] stop toolkit_obs_upload_by_channels_pid = 53 by signal SIGTERM" Component=ShellScripts Platform=ModelArts-Service
time="2023-10-13T16:17:17+08:00" level=info msg="the periodic upload task exiting..." file="upload.go:216" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=log_url
time="2023-10-13T16:18:53+08:00" level=info msg="the periodic upload task exiting..." file="upload.go:216" Command=obs/upload_by_channels Component=ma-training-toolkit Platform=ModelArts-Service Task=srt_log_collection
success